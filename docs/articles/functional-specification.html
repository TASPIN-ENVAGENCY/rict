<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>functional-specification • rict</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="functional-specification">
<meta property="og:description" content="rict">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">rict</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/functional-specification.html">functional-specification</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/aquaMetrics/rict/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="functional-specification_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>functional-specification</h1>
            
            <h4 class="date">2020-09-15</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/aquaMetrics/rict/blob/master/vignettes/functional-specification.Rmd"><code>vignettes/functional-specification.Rmd</code></a></small>
      <div class="hidden name"><code>functional-specification.Rmd</code></div>

    </div>

    
    
<style>
img {
border: 0px;
outline: 0 ;
}
</style>
<style>
img {
border: 0px;
outline: 0 ;
}
</style>
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>DRAFT!</p>
<div id="purpose-of-the-document" class="section level2">
<h2 class="hasAnchor">
<a href="#purpose-of-the-document" class="anchor"></a>Purpose of the document</h2>
<p>The purpose of this document is to define the business, functional and non-functional capabilities of RICT2 to support the design and implementation of RICT2 software tool.</p>
<p>The details will be sufficient to enable the software tool to be designed and built without having to continually refer queries to business representatives.</p>
<p>Further, it will be of sufficient detail to provide supporting documented information for any future RICT development.</p>
</div>
<div id="background" class="section level2">
<h2 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h2>
<p>The UK Regulatory Agencies have a requirement to classify ecological quality in rivers using data from invertebrate samples. The RIVPACS (River Invertebrate Prediction and Classification Tool) model and software tool, which was developed on behalf of the agencies by the Freshwater Biological Association (FBA) and subsequently by the Centre for Ecology and Hydrology (CEH), was originally used for this purpose. It incorporates a set of summarised reference data from sites assumed to be the best available of their type.</p>
<p>The EU Water Framework Directive (WFD) introduced in 2000, included modifications to the regulatory requirements in relation to classification and therefore the RIVPACS software processing tool had to be amended.</p>
<p>The original RIVPACS software tool was written in FORTRAN and had been developed in stages over a number of years. As a result, it was not written in a modern programming language and did not have flexibility to allow changes without significant cost. Therefore, a new tool was developed that allowed future changes to be made with minimal cost in many cases (e.g. the addition of a new index). This was the River Invertebrate Classification Tool (RICT) which went live in 2007. This version of RICT was a web-served application which was accessed via a website hosted by SEPA. The SEPA website also hosted copies of the manual, guidance and background documents.</p>
<p>RICT has had some updates since 2007, including the addition of ‘split season’ classification to enable WHPT (Walley, Hawkes, Paisley and Trigg) calculations using seasonal average EQRs (Ecological Quality Ratio). RICT was managed and hosted by Scottish Environment Protection Agency (SEPA) but is also used by Environment Agency (EA), Natural Resources Wales (NRW) and Northern Ireland Environment Agency (NIEA) as part of their regulatory and statutory requirements as well as public users such as academic institutions.</p>
<p>However, a number of issues were identified with this version of RICT which can be found in the outline business case produced by the scoping project. These include improving the performance, support arrangements and resilience as well as adding the new RIVPACS model (RIVPACS version IV) to the RICT tool, resolving critical bugs and other additional functionality. The full list of Critical success factors can be found in Annex C.</p>
<p>A shortlist of options to resolve the issues was discussed which resulted in the recommendation that RICT should adopt a Platform as a Service arrangement and run a modified application.</p>
<p>A new cloud-based open source version of RICT has been developed which will incorporate the current RIVPACS IV model and WFD status classification and uses the same basic algorithms to provide the same final results (other than correction of errors). Code and data tables for the new version will be more accessible to developers who wish to further develop RICT and their own project experiments. This new version of RICT is called RICT2 (version 1).</p>
<p>The platform chosen for RICT2 is Microsoft Azure Machine Learning (ML) Studio with open source R programming language as the development choice. Users will need to create a Microsoft Azure ML Studio account to allow them to access the RICT2 software tool. The majority of users will be able to use the free account subscription provided which allows adequate processing time for the number of runs required for a typical user. For more intensive RICT2 users, a monthly subscription account can be used on an ad-hoc basis, i.e. a user could subscribe for a month during the month when intensive processing is required, then unsubscribe the following month. This will keep costs minimal. Further, advanced users can create their own experiments and edit the R code or the pipeline process to suit their own computing needs.</p>
<p>The RICT2 service is accessible via ML with the latest documentation including the technical specification and user guide being hosted on a SharePoint site containing the link to the RICT2 tool along with information and guidance.</p>
</div>
</div>
<div id="functional-overview" class="section level1">
<h1 class="hasAnchor">
<a href="#functional-overview" class="anchor"></a>Functional Overview</h1>
<p>RICT2 is an application that implements the RIVPACS IV predictive model. The primary requirement of the tool is to allocate WFD (Water Framework Directive) compliant classifications to rivers with regard to the quality of the river invertebrate community.</p>
<p>The classifications are calculated and described as H() = high, G = good, M = moderate, P = poor or B = bad. This is achieved by comparing sample data from a river site against sample data previously taken from river sites considered to be the best available of their type.</p>
<p>The primary functions of the RICT2 tool are:</p>
<ol style="list-style-type: decimal">
<li><p>Predict - Predict the value of various biotic indices and (in a separate experiment) the presence and abundance of invertebrate species, genera or families that you would expect at any place on any stream or river in the UK if it was not environmentally disturbed.</p></li>
<li><p>Classify - Determine the Water Framework Directive (WFD) quality status class and statistical information about its confidence.</p></li>
<li><p>Compare - Compare the statistical significance of differences between classifications.</p></li>
</ol>
<p>It is to be capable of doing this for one or more sites at a time, with the results provided in an output file for subsequent processing by the relevant user.</p>
<p>Each operation of the tool is carried out within a project experiment which may cover anything from a single site up to all sites within the UK that require classification.</p>
<p>Standard experiments with default settings will be provided and made available on Microsoft Azure ML studio. RICT2 experiments will be collated as a “Collection” in Microsoft Azure Learning Studio to help users find all the experiments relevant to RICT2 as per the link below:</p>
<p><a href="https://gallery.azure.ai/Collection/River-Invertebrate-Classification-Tool-RICT-Current-Versions" class="uri">https://gallery.azure.ai/Collection/River-Invertebrate-Classification-Tool-RICT-Current-Versions</a></p>
<p>Users can amend and save these experiments in their own azure ML studio workspace to create a experiments to suit their own requirements. The R source code can also be download from <a href="https://github.com/aquaMetrics/rict">github</a> and edited in local R environment for example in Rstudio.</p>
<p>However, it must be noted that the version of R software studio on Microsoft Azure ML studio, at the time of writing this document, are currently older (latest being 3.4.4) than the latest version of R available. Therefore, if the experiment is downloaded and the user does some amendments to the R code using their latest version of the R, it may have compatibility issues if this experiment is subsequently uploaded back into Microsoft Azure ML studio.</p>
<p>It should be noted that this document is written from the expectation that the user will be running the experiment in Microsoft Azure ML studio.</p>
<p>For initial release, the GB Single year, GB multi-year and NI single year for WFD classification have been produced. These three experiments are available in the Azure ML Studio gallery.<strong>(chnage this section?)</strong></p>
<p>The diagram below shows a diagrammatical representation of the main functionality of the RICT2 tool with numbered links to more detailed information.</p>
<p><img src="images/application-flow-chart.png" width="666" height="481"></p>
<p><strong>1. LOGIN TO RICT:</strong> A new user will need to create a Microsoft account and log in to be able to access to the RICT tool as the tool uses the Microsoft Azure Machine Learning Studio as its platform. How to access RICT is outlined in the RICT user guide.</p>
<p><strong>2. COMPLETE DATA INPUT:</strong> User will need to complete a CSV (comma delimited) input file containing the data for the run required. A standard template excel spreadsheet will be provided to enter this data which can be downloaded via a SharePoint link from the website.</p>
<p>Validation will be done on the spreadsheet as the user enters the data via conditional formatting to warn the user if the data input will not meet certain validation limits.</p>
<p>Annex A of this document has a copy of the data input table in more detail.</p>
<p><strong>3. PROVIDE DATA:</strong> User will need to upload data into the RICT2 Tool and link the data to the project experiment in Microsoft Azure ML Studio.</p>
<p>Support file data tables and R code support functions will be contained within Microsoft Azure ML Studio and will be linked to the project experiment. Section 3 of this document describes the support file data tables and R code support functions in more detail.</p>
<p><strong>4. TRIGGER RUN:</strong> User can choose to run a project experiment for Predict and Classify experiment using the GB (Great Britain) model or a Predict and Classify experiment using the NI (Northern Ireland) model using default values.</p>
<p>Users can also choose to download and amend the standard default experiments, including amending the support file data table values and create their own experiments in their own work area to run.</p>
<p>Section 4 of this document describes the default values used in more detail.</p>
<p><strong>5. VALIDATE DATA:</strong> A series of validation checks to ensure data provided meets specified requirements will be carried out using R code in RICT2.</p>
<p>Section 5 of this document describes the validation steps in more detail.</p>
<p><strong>6. PREDICTION:</strong> Tool will perform a series of steps in the project experiment to calculate Prediction: * Convert Environmental Data * Calculate Probability of End Group Membership * Calculate Environmental Suitability * Calculate Predicted Index Values (WHPT indices only in predict &amp; classify experiments, multiple indices in a separate experiment) * Calculate Predicted Taxa (in a separate Experiment)</p>
<p>Section 6 and 7 of this document describe the conversion and prediction steps in more detail.</p>
<p><strong>7. CLASSIFICATION:</strong> Tool will perform a series of steps in the project experiment to calculate Classification:</p>
<ul>
<li>Calculate reference values from expected values</li>
<li>Apply bias to Observed Values</li>
<li>Run simulations to take account of errors in observed and expected</li>
<li>Calculate EQR for all simulations</li>
<li>Average spring and autumn EQR for all simulations</li>
<li>Calculate probability of class from the simulations</li>
</ul>
<p>Section 10 of this document describe the classification steps in more detail.</p>
<p><strong>9. COMPARE EXPERIMENT:</strong> Tool runs processing steps to compare data outputs from two previous predict and classify runs to produce a compare output file report.</p>
<p><strong>10. OUTPUT FILE:</strong> RICT2 will generate an output file with processed data for Predict and Classify in csv format for the user to download. This data extract can th en be used for analysis and reporting.</p>
<p>Annex B of this document has a copy of the data output table in more detail.</p>
<p>Users can also choose the R Device dataset option in Machine studio to visualise the data and, if required, could write code to create the output file in the format they choose.</p>
<p>A screenshot of the RICT2 prediction and classification experiment for GB in Microsoft Azure ML Studio being used with the default GB test data from the input template is shown below:</p>
</div>
<div id="supporting-files" class="section level1">
<h1 class="hasAnchor">
<a href="#supporting-files" class="anchor"></a>Supporting files</h1>
<p>RICT2 uses the RIVPACS reference data which contain sites that are considered to be the best available of their type. The latest version of the complete RIVPACS reference database for RICT can be downloaded from the RICT2 Website:</p>
<p><a href="https://fba.org.uk/FBA/Public/Discover-and-Learn/Projects/RIVPACS-Reference-Sites-and-Reports.aspx" class="uri">https://fba.org.uk/FBA/Public/Discover-and-Learn/Projects/RIVPACS-Reference-Sites-and-Reports.aspx</a></p>
<p>Within RICT2, the RIVPACS reference data is not used at site level but is used at the End Group level, where an End Group contains combined data for sites considered to be of a similar biological composition. End Groups are grouped up to End Group Sets (e.g. New GB – 43 Group level).</p>
<p>As well as this data table, RICT2 needs other data which will be held and used as internal data tables and R software code functions in the project experiment.</p>
<p>A list of the tables and functions required for the <strong>GB model experiment</strong> is as below.</p>
<p>All the following files can be found within the rict package on <a href="https://github.com/aquaMetrics/rict">github</a>.</p>
<p>Each experiment uses the exact same supporting file/package. The code within each experiment determines which functions and supporting table are called from the rict package.</p>
<p>The rict package is automatically tested and compiled/built on every update to the master branch on github. This process is carried out by the Appveyor website, which monitors github for any changes and re-builds and tests the code on a Windows machine in the cloud.</p>
<p>The Microsoft Windows binary .zip package file (Azure requires a Windows binary package) is stored on the Appveyor <a href="https://ci.appveyor.com/project/ecodata1/rict/branch/master/artifacts">artifacts</a> page. It is currently built using R 3.5 (slight above the Azure version 3.4.4) for compatibility with Appveyor. But this has not caused any issues. Alternatively, the rict package binary can be compile/built locally on a Windows machine.</p>
<p>The .zip binary package file, is then moved to a folder called ‘support-files’ and that folder is also zip compressed. This zipped folder is then uploaded to Azure Studio experiments as required.</p>
<div id="prediction" class="section level2">
<h2 class="hasAnchor">
<a href="#prediction" class="anchor"></a>Prediction</h2>
<div id="support-tables" class="section level3">
<h3 class="hasAnchor">
<a href="#support-tables" class="anchor"></a>Support Tables:</h3>
<p>These files can be found in the inst/extdat folder within the rict package.</p>
<p><strong>Model 1 specific:</strong></p>
<ul>
<li>
<code>df-coeff-gb-685.DAT</code> – used for Discriminant score.</li>
<li>
<code>df-mean-gb-685.DAT</code> - used for calculating Mahanalobis distance.</li>
</ul>
<p><strong>Model 44 specific:</strong></p>
<ul>
<li>
<code>discrimintant-function-coefficient-model-44.csv</code> - used for discriminant score.</li>
<li>
<code>discrimantinant-function-model-44.csv</code> file used for calculating Mahanalobis distance.</li>
</ul>
<p><strong>For both models:</strong></p>
<ul>
<li>
<code>air-temp-grid.csv</code> – contains previously derived Environmental data values for the Mean Air Temperature (TEMPM) and Temperature range (TEMPR) for points in the centres of 5km interval grid squares. Values are used after converting the supplied NGR (or BNR) to latitude and longitude to identify the relevant values required.</li>
<li>
<code>end-grp-assess-scores.csv</code> used for calculating proportion during prediction.</li>
<li>
<code>TAXA_AB_APR_PRAB.csv</code> - containing abundance and probability of abundance category for each taxon used in predicting taxa.</li>
<li>
<code>x103-end-group-means.csv</code> – combined data for sites considered to be of a similar biological compositionthe End Group table used in RICT2 is called</li>
</ul>
</div>
<div id="prediction-functions" class="section level3">
<h3 class="hasAnchor">
<a href="#prediction-functions" class="anchor"></a>Prediction Functions:</h3>
<p>Found in the <code>/R</code> package directory there are two main R functions files for predictions:</p>
<p><code>rict-predict.R</code> - main function called to run prediction<br><code>rict-validate.R</code> - lower level function to validate input data <code>helper-functions.R</code> - support functions to carry out the Environmental Variables validation</p>
<p>Prediction support functions are found:</p>
<p><code>prediction-functions.R</code><br><code>calc_temperatures.R</code></p>
</div>
<div id="prediction-of-the-all-80-indices-diagramflow-for-gb" class="section level3">
<h3 class="hasAnchor">
<a href="#prediction-of-the-all-80-indices-diagramflow-for-gb" class="anchor"></a>Prediction of the all 80 indices diagram/flow for GB</h3>
</div>
</div>
<div id="classification" class="section level2">
<h2 class="hasAnchor">
<a href="#classification" class="anchor"></a>Classification</h2>
<div id="files-supporting" class="section level3">
<h3 class="hasAnchor">
<a href="#files-supporting" class="anchor"></a>Files Supporting:</h3>
<ul>
<li>
<code>adjustParams_ntaxa_aspt.csv</code> - reference adjustment values.</li>
<li>
<code>EndGrp_AssessScores.csv</code> - Excel csv used for adjusting the expected values during classification for calculating proportion.</li>
</ul>
<p><strong>Note</strong>, no classification is carried out on the 80 indices – the experiment is carried out for Prediction only!</p>
<p>A list of the tables and functions required for the NI model experiment is as below: Prediction support files:</p>
<ul>
<li>
<code>DFCOEFF_NI.DAT</code> file used for Discriminant score as described in section 7.5 of this document.</li>
<li>
<code>DFMEAN_NI_RALPH.DAT</code> file used for calculating Mahanalobis distance as described in section 7.6 of this document.j</li>
<li>
<code>EndGrp_AssessScores.csv</code> file used for calculating proportion during prediction.</li>
</ul>
</div>
<div id="classification-functions" class="section level3">
<h3 class="hasAnchor">
<a href="#classification-functions" class="anchor"></a>Classification Functions:</h3>
<ul>
<li>
<code>classification-functions.R</code> - A large number of R code functions used during the prediction process as described in Section 8.</li>
</ul>
</div>
<div id="prediction-of-the-all-80-indices-diagramflow-for-ni" class="section level3">
<h3 class="hasAnchor">
<a href="#prediction-of-the-all-80-indices-diagramflow-for-ni" class="anchor"></a>Prediction of the all 80 indices diagram/flow for NI</h3>
<p>Classification support files:</p>
<ul>
<li>
<code>adjustParams_ntaxa_aspt.csv</code> containing reference adjustment values which are used as described in Section 8.2.</li>
<li>
<code>EndGrp_AssessScoresNI.csv</code> used for adjusting the expected values during classification as described in Section 8.2.</li>
</ul>
<p>All source code and support files can be downloaded into R environment for example Rstudio from github for users who wish to amend and create their own versions and set up their own experiments.</p>
</div>
</div>
</div>
<div id="rict2-experiments" class="section level1">
<h1 class="hasAnchor">
<a href="#rict2-experiments" class="anchor"></a>RICT2 Experiments</h1>
<div id="introduction-1" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction-1" class="anchor"></a>Introduction</h2>
<p>The “settings” will be determined by the project experiment which will use default values relevant for that project experiment. However, the tool will allow a user to open experiments in their own workspace and change the settings and values and save their own experiments. Standard published experiments can only be amended by an administrator user. These will be a “locked down” version displayed in the Azure Studio gallery.</p>
<p>Below are described the default settings values for the WFD Classification experiments.</p>
<p>A run of the tool can only be carried out against one Reference End Group model. Users can choose to run an experiment for either:</p>
<ul>
<li>RIVPACS IV GB (M1) (Set ID = 1)</li>
<li>RIVPACS IV NI (M1) (Set ID = 2)</li>
</ul>
</div>
<div id="default-values" class="section level2">
<h2 class="hasAnchor">
<a href="#default-values" class="anchor"></a>Default values</h2>
<p>The list below describes the default values used:</p>
<ul>
<li>Number of Monte-Carlo simulations – 10,000</li>
<li>Index sets – all 80 indices</li>
<li>Season type – Spring, Autumn, Spring/Autumn Combined, Summer</li>
<li>Classification boundary limits – Coded as per WFD compliant values found in the classification support files (user would need to amend the function in this file to alter values for their own experiments) <strong>(Make this a parameter? - TF)</strong>
</li>
<li>Bias - Bias values can be provided in the input file by the user and will be used in the experiment if they have been provided. However, if no data values for Bias or “-9” has been entered in the input file, then the hard-coded default value of 1.62 (GB) or 0 (NI) will be used.</li>
</ul>
<p>Note that 1.62 is the default value currently being used for Bias as this was input as the default value in the previous version of RICT2 as used in SEPA for BMWP NTAXA. However, the EA uses a value of 1.68 as the Bias value for WHPT which was based on an audit of the analytical quality of Environment Agency laboratories. The Bias value for WHPT should be greater than the value for BMWP for the same level of analytical quality, because WHPT uses more taxa than BMWP. Plus WHPT taxa also includes additional Diptera families which are less easy to identify.</p>
</div>
<div id="future-experiments" class="section level2">
<h2 class="hasAnchor">
<a href="#future-experiments" class="anchor"></a>Future Experiments</h2>
<p>A multi-site classification will be added to enable water bodies to be classified from more than one site. The GIS data location checker and delivery system and multi-site classification are currently in development and we hope to release them in a couple of months.</p>
<p>We may need to modify Compare to allow individual-season estimates of class for spring and autumn to be compared, as that is used in conjunction with the official combined season classification for evaluating the impact of combined sewer overflows</p>
<p>Additional standard default experiments to calculate the output for more specific Index sets (e.g. for hydro-ecological evaluation) may be added later, if the need arises.</p>
<p>Future RICT2 release may allow a user to run predictions and classifications against previous classifications and RIVPACS models to allow historical data to be analysed in a consistent way with current monitoring data. That may include BMWP (Biological Monitoring Working Party) classification based on RIVPACS IV (used before 2015) or RIVPACS III+ (used 1990-1009), or using WHPT based on BMWP taxa including BMWP composite taxa.</p>
<p>We may also correct or improve experiments. If we need to do that, or we add new experiments to the gallery, we will run them through testing to ensure that the modifications do not affect the results and if they do, we know what the effect is. Information about that will be added to this document and to user guides, as appropriate.</p>
</div>
<div id="acceptance-and-validation-of-input-data" class="section level2">
<h2 class="hasAnchor">
<a href="#acceptance-and-validation-of-input-data" class="anchor"></a>Acceptance and validation of input data</h2>
<p>In order to be able to predict and classify, the tool requires input data in one csv file which includes:</p>
<ul>
<li>Site Identifier</li>
<li>Values for a number of Environmental Variables (e.g. NGR, width, depth, etc.)</li>
<li>Values for a number of Observed Tool Indices (e.g. ASPT, NTAXA, etc.) (only required for classification)</li>
</ul>
<p>An excel spreadsheet template will be provided for the user to enter input data into the relevant column headings. Validation rules will be applied to the data that has been input for each column to help the user meet the validation requirements detailed below.</p>
<p>The input data spreadsheet template can be found in Annex A of this document. Once completed, this spreadsheet will need to be saved as a csv format and uploaded by the user to link to the required project experiment.</p>
</div>
<div id="environmental-variable-values-and-validation" class="section level2">
<h2 class="hasAnchor">
<a href="#environmental-variable-values-and-validation" class="anchor"></a>Environmental Variable Values and Validation</h2>
<p>Environmental Variables (EV) are needed to enable the prediction process to calculate the probability of end group membership. The values of some Environmental Variables are provided and input by the user. The values of other Environmental Variables have to be derived using the values of one or more provided Environmental Variables and then converted. The complete set of input and derived Environmental Variables used by RICT2 are called Predictive Environmental Variables (PEVs).</p>
<p>The table below refers to the Environmental Variable data required and the data field validation for the RIVPACS IV Great Britain Model M1 which requires input of 13 PEVs and for the RIVPACS IV Northern Ireland Model M1 which requires input of 11 PEVs.</p>
<p>Input file screening will be carried out using the rules described in the table below when a user enters data into the input file spreadsheet. This will be done by the conditional formatting tool within the MS Excel ribbon to check and highlight to the user where data does not meet validation requirements. It will highlight failures in red and warnings in orange. However, it will not stop the user from supplying that data to RICT2 for processing. When RICT2 processes the data, the appropriate Fail and Warn errors will be generated as described below.</p>
<p>Validation has also been coded into RICT2 for validation of the value ranges, i.e. “all”, “gb” and “ni”.</p>
<p>Note that at least one set of the following data will be required for each site but there may be up to three sets of data where the ‘raw’ data is being provided for up to three years for multi-year classification.</p>
</div>
<div id="input-variables" class="section level2">
<h2 class="hasAnchor">
<a href="#input-variables" class="anchor"></a>Input variables</h2>
<p>All input variables as well as their validation rules are listed in the validation-rules.csv file within the package. The tables below are generated from this file.</p>
<div id="model-1-user-input-file-using-physical-predictors" class="section level3">
<h3 class="hasAnchor">
<a href="#model-1-user-input-file-using-physical-predictors" class="anchor"></a>Model 1 User input file (using physical predictors)</h3>
<p>Required columns:</p>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="left">Variable</th>
<th align="left">Units</th>
<th align="left">Description</th>
<th align="left">Type</th>
<th align="left">Optional</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">SITE</td>
<td align="left"></td>
<td align="left">Site</td>
<td align="left">character</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">WATERBODY</td>
<td align="left"></td>
<td align="left">Waterbody</td>
<td align="left">character</td>
<td align="left">TRUE</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">YEAR</td>
<td align="left"></td>
<td align="left">Year</td>
<td align="left">integer</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">NGR</td>
<td align="left"></td>
<td align="left">National Grid Reference</td>
<td align="left">character</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">EASTING</td>
<td align="left">m</td>
<td align="left">Easting</td>
<td align="left">character</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">NORTHING</td>
<td align="left">m</td>
<td align="left">Northing</td>
<td align="left">character</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">7</td>
<td align="left">ALTITUDE</td>
<td align="left">m</td>
<td align="left">Altitude</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">9</td>
<td align="left">SLOPE</td>
<td align="left">m/km</td>
<td align="left">Slope at site</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">11</td>
<td align="left">DISCHARGE</td>
<td align="left"></td>
<td align="left">Discharge category</td>
<td align="left">numeric</td>
<td align="left">TRUE</td>
</tr>
<tr class="even">
<td align="left">13</td>
<td align="left">VELOCITY</td>
<td align="left">m/s</td>
<td align="left">Velocity</td>
<td align="left">numeric</td>
<td align="left">TRUE</td>
</tr>
<tr class="odd">
<td align="left">15</td>
<td align="left">DIST_FROM_SOURCE</td>
<td align="left">m/km</td>
<td align="left">Distance from Source</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">17</td>
<td align="left">MEAN_WIDTH</td>
<td align="left">m</td>
<td align="left">Stream Width</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">19</td>
<td align="left">MEAN_DEPTH</td>
<td align="left">cm</td>
<td align="left">Stream Depth</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">21</td>
<td align="left">BOULDER_COBBLES</td>
<td align="left">%</td>
<td align="left">Boulder Cobble Percentage</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">22</td>
<td align="left">PEBBLES_GRAVEL</td>
<td align="left">%</td>
<td align="left">Pebbles Gravel Percentage</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">23</td>
<td align="left">SAND</td>
<td align="left">%</td>
<td align="left">Sand Percentage</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">24</td>
<td align="left">SILT_CLAY</td>
<td align="left">%</td>
<td align="left">Silt Clay Percentage</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">25</td>
<td align="left">HARDNESS</td>
<td align="left">%</td>
<td align="left">Mean substratum</td>
<td align="left">numeric</td>
<td align="left">TRUE</td>
</tr>
<tr class="odd">
<td align="left">26</td>
<td align="left">CALCIUM</td>
<td align="left"></td>
<td align="left">Calcium concentration</td>
<td align="left">numeric</td>
<td align="left">TRUE</td>
</tr>
<tr class="even">
<td align="left">27</td>
<td align="left">CONDUCTIVITY</td>
<td align="left"></td>
<td align="left">Electrical Conductivity</td>
<td align="left">numeric</td>
<td align="left">TRUE</td>
</tr>
<tr class="odd">
<td align="left">28</td>
<td align="left">ALKALINITY</td>
<td align="left">mg/L</td>
<td align="left">Alkalinity as CaCO3</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
</tbody>
</table>
</div>
<div id="model-44-input-files-using-gis-predictors" class="section level3">
<h3 class="hasAnchor">
<a href="#model-44-input-files-using-gis-predictors" class="anchor"></a>Model 44 Input files (using GIS predictors)</h3>
<p>Required columns:</p>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="left">Variable</th>
<th align="left">Units</th>
<th align="left">Description</th>
<th align="left">Type</th>
<th align="left">Optional</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">SITE</td>
<td align="left"></td>
<td align="left">Site</td>
<td align="left">character</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">WATERBODY</td>
<td align="left"></td>
<td align="left">Waterbody</td>
<td align="left">character</td>
<td align="left">TRUE</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">YEAR</td>
<td align="left"></td>
<td align="left">Year</td>
<td align="left">integer</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">ALKALINITY</td>
<td align="left">mg/L</td>
<td align="left">Alkalinity as CaCO3</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">6</td>
<td align="left">PEAT</td>
<td align="left">Proportion</td>
<td align="left">Peat</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">7</td>
<td align="left">CHALK</td>
<td align="left">Proportion</td>
<td align="left">Chalk</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">8</td>
<td align="left">CLAY</td>
<td align="left">Proportion</td>
<td align="left">Clay</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">9</td>
<td align="left">HARDROCK</td>
<td align="left">Proportion</td>
<td align="left">Hardrock</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">10</td>
<td align="left">LIMESTONE</td>
<td align="left">Proportion</td>
<td align="left">Limestone</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">11</td>
<td align="left">LOG_AREA</td>
<td align="left">Log (km2)</td>
<td align="left">Log Area</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">12</td>
<td align="left">LOGALTBAR</td>
<td align="left">Metres</td>
<td align="left">Mean Altitude of Catchment</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">13</td>
<td align="left">ALTITUDE</td>
<td align="left">Metres</td>
<td align="left">Site Altitude</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">14</td>
<td align="left">D_F_SOURCE</td>
<td align="left">km</td>
<td align="left">Distance from Source</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">15</td>
<td align="left">SLOPE</td>
<td align="left">m/km</td>
<td align="left">Slope at site</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">16</td>
<td align="left">SX</td>
<td align="left"></td>
<td align="left">Sampling site X coordinate (BNG)</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">17</td>
<td align="left">SY</td>
<td align="left"></td>
<td align="left">Sampling site Y coordinate (BNG)</td>
<td align="left">numeric</td>
<td align="left">FALSE</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="optional-variables" class="section level2">
<h2 class="hasAnchor">
<a href="#optional-variables" class="anchor"></a>Optional variables</h2>
<p>Optional columns: Must still be present in input data file but they may contain missing values or be entirely empty. However, they must comply with the following notes:</p>
<div id="model-1-optional-notes" class="section level3">
<h3 class="hasAnchor">
<a href="#model-1-optional-notes" class="anchor"></a>Model 1 Optional notes:</h3>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="left">Variable</th>
<th align="left">Optional note</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">DISCHARGE</td>
<td align="left">One of DISCHARGE or VELOCITY</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">VELOCITY</td>
<td align="left">One of DISCHARGE or VELOCITY</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">HARDNESS</td>
<td align="left">One of Alkalinity, Hardness, Conductivity or Calcium</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">CALCIUM</td>
<td align="left">One of Alkalinity, Hardness, Conductivity or Calcium</td>
</tr>
<tr class="odd">
<td align="left">7</td>
<td align="left">CONDUCTIVITY</td>
<td align="left">One of Alkalinity, Hardness, Conductivity or Calcium</td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="left">ALKALINITY</td>
<td align="left">One of Alkalinity, Hardness, Conductivity or Calcium</td>
</tr>
</tbody>
</table>
</div>
<div id="model-44-optional-notes" class="section level3">
<h3 class="hasAnchor">
<a href="#model-44-optional-notes" class="anchor"></a>Model 44 Optional notes:</h3>
<table class="table">
<thead><tr class="header">
<th align="left">Variable</th>
<th align="left">Optional note</th>
</tr></thead>
<tbody><tr class="odd">
<td align="left">ALKALINITY</td>
<td align="left">One of Alkalinity, Hardness, Conductivity or Calcium</td>
</tr></tbody>
</table>
</div>
</div>
<div id="validation" class="section level2">
<h2 class="hasAnchor">
<a href="#validation" class="anchor"></a>Validation</h2>
<p>Warnings: Where the value of an environmental input variable exceeds a “Warn” limit, the prediction process will continue but warning message is created for that particular site.</p>
<p>Fails: Where the value of an environmental input variable exceeds a “Fail” limit, the prediction process will not proceed for that particular site and flags the transgression in a fail message.</p>
<div id="validation-rules-for-model-1" class="section level3">
<h3 class="hasAnchor">
<a href="#validation-rules-for-model-1" class="anchor"></a>Validation rules for Model 1</h3>
<table class="table">
<colgroup>
<col width="19%">
<col width="5%">
<col width="17%">
<col width="20%">
<col width="17%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th align="left">Variable</th>
<th align="left">Area</th>
<th align="right">Less than fail</th>
<th align="right">Greater than fail</th>
<th align="right">Less than warn</th>
<th align="right">Greater than warn</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">SITE</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">WATERBODY</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">YEAR</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">1990.0</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">NGR</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">EASTING</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">NORTHING</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">ALTITUDE</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">1345</td>
<td align="right">0.0</td>
<td align="right">590.0</td>
</tr>
<tr class="even">
<td align="left">ALTITUDE</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">1345</td>
<td align="right">3.0</td>
<td align="right">180.0</td>
</tr>
<tr class="odd">
<td align="left">SLOPE</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">0.0</td>
<td align="right">150.0</td>
</tr>
<tr class="even">
<td align="left">SLOPE</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">0.1</td>
<td align="right">50.0</td>
</tr>
<tr class="odd">
<td align="left">DISCHARGE</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">10</td>
<td align="right">1.0</td>
<td align="right">10.0</td>
</tr>
<tr class="even">
<td align="left">DISCHARGE</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">10</td>
<td align="right">1.0</td>
<td align="right">8.0</td>
</tr>
<tr class="odd">
<td align="left">VELOCITY</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">5</td>
<td align="right">1.0</td>
<td align="right">5.0</td>
</tr>
<tr class="even">
<td align="left">VELOCITY</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">5</td>
<td align="right">1.0</td>
<td align="right">5.0</td>
</tr>
<tr class="odd">
<td align="left">DIST_FROM_SOURCE</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">0.1</td>
<td align="right">202.8</td>
</tr>
<tr class="even">
<td align="left">DIST_FROM_SOURCE</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">2.2</td>
<td align="right">75.0</td>
</tr>
<tr class="odd">
<td align="left">MEAN_WIDTH</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">0.4</td>
<td align="right">117.0</td>
</tr>
<tr class="even">
<td align="left">MEAN_WIDTH</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">2.0</td>
<td align="right">37.0</td>
</tr>
<tr class="odd">
<td align="left">MEAN_DEPTH</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">1.7</td>
<td align="right">300.0</td>
</tr>
<tr class="even">
<td align="left">MEAN_DEPTH</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">15.0</td>
<td align="right">183.0</td>
</tr>
<tr class="odd">
<td align="left">BOULDER_COBBLES</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">100</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">PEBBLES_GRAVEL</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">100</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">SAND</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">100</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">SILT_CLAY</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">100</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">HARDNESS</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">CALCIUM</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">CONDUCTIVITY</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ALKALINITY</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">0.7</td>
<td align="right">365.5</td>
</tr>
<tr class="odd">
<td align="left">ALKALINITY</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">2.5</td>
<td align="right">193.5</td>
</tr>
</tbody>
</table>
<p>Model 1 Validation notes:</p>
<table class="table">
<colgroup>
<col width="6%">
<col width="93%">
</colgroup>
<thead><tr class="header">
<th align="left">Variable</th>
<th align="left">Validation notes</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">YEAR</td>
<td align="left">Warn if samples collected prior to 1990 as unlikely to be collected using RIVPACS method</td>
</tr>
<tr class="even">
<td align="left">NGR</td>
<td align="left">Must be less than 3 letters, can be upper or lower case</td>
</tr>
<tr class="odd">
<td align="left">EASTING</td>
<td align="left">Must be 5 digits; text not number, to retain leading zeros (input file screening). In R Code: If less than 5 digits add leading zeros</td>
</tr>
<tr class="even">
<td align="left">NORTHING</td>
<td align="left">Must be 5 digits; text not number, to retain leading zeros (input file screening). In R Code: If less than 5 digits add leading zeros</td>
</tr>
</tbody>
</table>
</div>
<div id="validation-rules-for-model-44" class="section level3">
<h3 class="hasAnchor">
<a href="#validation-rules-for-model-44" class="anchor"></a>Validation rules for Model 44</h3>
<table class="table">
<colgroup>
<col width="13%">
<col width="6%">
<col width="18%">
<col width="21%">
<col width="18%">
<col width="21%">
</colgroup>
<thead><tr class="header">
<th align="left">Variable</th>
<th align="left">Area</th>
<th align="right">Less than fail</th>
<th align="right">Greater than fail</th>
<th align="right">Less than warn</th>
<th align="right">Greater than warn</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">SITE</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">WATERBODY</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">YEAR</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">1990.0000</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ALKALINITY</td>
<td align="left">gb</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">0.7000</td>
<td align="right">366</td>
</tr>
<tr class="odd">
<td align="left">ALKALINITY</td>
<td align="left">ni</td>
<td align="right">0</td>
<td align="right">NA</td>
<td align="right">0.7000</td>
<td align="right">194</td>
</tr>
<tr class="even">
<td align="left">PEAT</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">CHALK</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">CLAY</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">HARDROCK</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">LIMESTONE</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">LOG_AREA</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">0.0724</td>
<td align="right">7193</td>
</tr>
<tr class="even">
<td align="left">LOGALTBAR</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">1.3800</td>
<td align="right">730</td>
</tr>
<tr class="odd">
<td align="left">ALTITUDE</td>
<td align="left">all</td>
<td align="right">-3</td>
<td align="right">1346.00</td>
<td align="right">0.0000</td>
<td align="right">597</td>
</tr>
<tr class="even">
<td align="left">D_F_SOURCE</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">296037.00</td>
<td align="right">0.1000</td>
<td align="right">245</td>
</tr>
<tr class="odd">
<td align="left">SLOPE</td>
<td align="left">all</td>
<td align="right">0</td>
<td align="right">1576.85</td>
<td align="right">0.1000</td>
<td align="right">142</td>
</tr>
<tr class="even">
<td align="left">SX</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">SY</td>
<td align="left">all</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>Model 44 validation notes:</p>
<table class="table">
<colgroup>
<col width="10%">
<col width="89%">
</colgroup>
<thead><tr class="header">
<th align="left">Variable</th>
<th align="left">Validation notes</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">YEAR</td>
<td align="left">Warn if samples collected prior to 1990 as unlikely to be collected using RIVPACS method</td>
</tr>
<tr class="even">
<td align="left">CHALK</td>
<td align="left">Combined proportion figure for chalk, clay, hardrock and limestone cannot be more than 1</td>
</tr>
<tr class="odd">
<td align="left">CLAY</td>
<td align="left">Combined proportion figure for chalk, clay, hardrock and limestone cannot be more than 1</td>
</tr>
<tr class="even">
<td align="left">HARDROCK</td>
<td align="left">Combined proportion figure for chalk, clay, hardrock and limestone cannot be more than 1</td>
</tr>
<tr class="odd">
<td align="left">LIMESTONE</td>
<td align="left">Combined proportion figure for chalk, clay, hardrock and limestone cannot be more than 1</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="replacement-values" class="section level2">
<h2 class="hasAnchor">
<a href="#replacement-values" class="anchor"></a>Replacement values</h2>
<p>If values are provided that are zero (or close to zero) they are replaced to avoid divide by zero errors. Specifically, variables that are used in the RIVPACS model discriminator functions in their log form (as you cannot take logs of zeroes):</p>
<table class="table">
<thead><tr class="header">
<th align="left">Variable</th>
<th align="left">Model</th>
<th align="left">Area</th>
<th align="right">Replacement value</th>
<th align="left">Replacement condition</th>
<th align="right">Replacement limit</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">ALTITUDE</td>
<td align="left">physical</td>
<td align="left">gb</td>
<td align="right">1.0</td>
<td align="left">equals</td>
<td align="right">0.0</td>
</tr>
<tr class="even">
<td align="left">ALTITUDE</td>
<td align="left">physical</td>
<td align="left">ni</td>
<td align="right">1.0</td>
<td align="left">equals</td>
<td align="right">0.0</td>
</tr>
<tr class="odd">
<td align="left">SLOPE</td>
<td align="left">physical</td>
<td align="left">gb</td>
<td align="right">0.1</td>
<td align="left">equals</td>
<td align="right">0.0</td>
</tr>
<tr class="even">
<td align="left">SLOPE</td>
<td align="left">physical</td>
<td align="left">ni</td>
<td align="right">0.1</td>
<td align="left">equals</td>
<td align="right">0.0</td>
</tr>
<tr class="odd">
<td align="left">DISCHARGE</td>
<td align="left">physical</td>
<td align="left">gb</td>
<td align="right">1.0</td>
<td align="left">equals</td>
<td align="right">0.0</td>
</tr>
<tr class="even">
<td align="left">DISCHARGE</td>
<td align="left">physical</td>
<td align="left">ni</td>
<td align="right">1.0</td>
<td align="left">equals</td>
<td align="right">0.0</td>
</tr>
<tr class="odd">
<td align="left">DIST_FROM_SOURCE</td>
<td align="left">physical</td>
<td align="left">gb</td>
<td align="right">0.1</td>
<td align="left">lessthan</td>
<td align="right">0.1</td>
</tr>
<tr class="even">
<td align="left">DIST_FROM_SOURCE</td>
<td align="left">physical</td>
<td align="left">ni</td>
<td align="right">0.1</td>
<td align="left">lessthan</td>
<td align="right">0.1</td>
</tr>
<tr class="odd">
<td align="left">MEAN_WIDTH</td>
<td align="left">physical</td>
<td align="left">gb</td>
<td align="right">0.1</td>
<td align="left">lessthan</td>
<td align="right">0.1</td>
</tr>
<tr class="even">
<td align="left">MEAN_WIDTH</td>
<td align="left">physical</td>
<td align="left">ni</td>
<td align="right">0.1</td>
<td align="left">lessthan</td>
<td align="right">0.1</td>
</tr>
<tr class="odd">
<td align="left">MEAN_DEPTH</td>
<td align="left">physical</td>
<td align="left">gb</td>
<td align="right">1.0</td>
<td align="left">lessthan</td>
<td align="right">1.0</td>
</tr>
<tr class="even">
<td align="left">MEAN_DEPTH</td>
<td align="left">physical</td>
<td align="left">ni</td>
<td align="right">1.0</td>
<td align="left">lessthan</td>
<td align="right">1.0</td>
</tr>
<tr class="odd">
<td align="left">ALKALINITY</td>
<td align="left">physical</td>
<td align="left">gb</td>
<td align="right">0.1</td>
<td align="left">lessthan</td>
<td align="right">0.1</td>
</tr>
<tr class="even">
<td align="left">ALKALINITY</td>
<td align="left">physical</td>
<td align="left">ni</td>
<td align="right">0.1</td>
<td align="left">lessthan</td>
<td align="right">0.1</td>
</tr>
<tr class="odd">
<td align="left">ALKALINITY</td>
<td align="left">gis</td>
<td align="left">gb</td>
<td align="right">0.1</td>
<td align="left">lessthan</td>
<td align="right">0.1</td>
</tr>
<tr class="even">
<td align="left">ALKALINITY</td>
<td align="left">gis</td>
<td align="left">ni</td>
<td align="right">0.1</td>
<td align="left">lessthan</td>
<td align="right">0.1</td>
</tr>
<tr class="odd">
<td align="left">ALTITUDE</td>
<td align="left">gis</td>
<td align="left">all</td>
<td align="right">1.0</td>
<td align="left">equals</td>
<td align="right">0.0</td>
</tr>
<tr class="even">
<td align="left">D_F_SOURCE</td>
<td align="left">gis</td>
<td align="left">all</td>
<td align="right">0.1</td>
<td align="left">equals</td>
<td align="right">0.1</td>
</tr>
<tr class="odd">
<td align="left">SLOPE</td>
<td align="left">gis</td>
<td align="left">all</td>
<td align="right">0.1</td>
<td align="left">equals</td>
<td align="right">0.0</td>
</tr>
</tbody>
</table>
</div>
<div id="validation-rules" class="section level2">
<h2 class="hasAnchor">
<a href="#validation-rules" class="anchor"></a>Validation rules</h2>
<p>The min/max validation rules are stores in the <code>validation-rules.csv</code>. This can be updated with new min/max validation as required. The more complex validation rules for example checking the presence of optional columns are hard-coded into the <code>rict_validation()</code> function.</p>
</div>
<div id="environmental-variables-validation-process" class="section level2">
<h2 class="hasAnchor">
<a href="#environmental-variables-validation-process" class="anchor"></a>Environmental Variables Validation Process</h2>
<p>Some initial validation is done if the user (as recommended) enters data into the input spreadsheet:</p>
<ul>
<li>Spreadsheet validation is carried out to check that the Environmental Values are present and they are the correct format as user enters data.</li>
</ul>
<p>The user then inputs the values into RICT2 on Azure and the software carries out further validation:</p>
<p>If any columns are missing when data is imported to RICT2 the program fails.</p>
<ul>
<li>Check against ‘Overall’ Valid Max/Min Values</li>
<li>Check that each provided EV value is greater than or equal to the ‘overall’ minimum value and less than or equal to the ‘overall’ maximum value defined in the Environmenjtal Variable parameter table above.</li>
<li>Within RICT2 code, if the values do not meet the validation criteria the site is flagged as a failure and that particular site is removed from the experiment.</li>
</ul>
<p>The fail limits are based on the minimum and maximum values likely in GB or NI. Values exceeding these limits must be wrong.</p>
<ul>
<li>Check against ‘Warning’ Max/Min Values</li>
<li>Check that each provided EV value is greater than or equal to the ‘warning’ minimum value and less than or equal to the ‘warning’ maximum value defined in the Environmental Variable parameter table above.</li>
<li>If not, then this should be recorded so that it can be flagged as a ‘warning’ in the output file but the experiment will proceed as normal.</li>
</ul>
<p>The warning limits are the minimum and maximum values of the variables in the RIVPACS reference database for reference sites included in RIVPACS IV GB or NI. Exceedences indicate that the site is beyond the scope of the model and may be the cause of poor suitability and they could indicate errors. Exceeding longitude and latitude is less serious that exceeding other parameters.</p>
</div>
<div id="observed-biological-data-values-and-validation" class="section level2">
<h2 class="hasAnchor">
<a href="#observed-biological-data-values-and-validation" class="anchor"></a>Observed Biological Data Values and Validation</h2>
<p>Biological data is needed to enable the classification process. The values of the Biological data is provided by the user.</p>
<p>The table below refers to the data items required and the data field validation for the RIVPACS IV Great Britain Model 1 and for the RIVPACS IV Northern Ireland Model 1.</p>
<p>Conditional formatting validation will be carried out for all of the validation rules described in the table below when a user enters data into the input file spreadsheet. There is no validation for the Observed Biological data within RICT2.</p>
<p>However, RICT2 will validate that relevant values have been provided from the prediction process of the experiment prior to the classification process. This is to check that there are no null values if these values are required for the classification to be successful.</p>
<p>Note, this data will need to be entered for each season relevant for the project experiment. For WFD classification, this will be data for spring and autumn.</p>
<p>Data Item<br>
Validation<br>
Season ID</p>
<p>Season_ID must be numeric single digit code, i.e. from list:</p>
<ul>
<li>1 = spring</li>
<li>2 = summer<br>
</li>
<li>3 = autumn<br>
</li>
<li>4 = spring + summer<br>
</li>
<li>5 = spring + autumn<br>
</li>
<li>6 = summer + autumn<br>
</li>
<li>7 = spring + summer + autumn</li>
</ul>
<p>See All Indices table with new labels<br>
Must be numeric integer (i.e. whole number)<br>
Bias (Ntaxa_Bias) Must be numeric</p>
</div>
<div id="conversion-of-input-environmental-variables" class="section level2">
<h2 class="hasAnchor">
<a href="#conversion-of-input-environmental-variables" class="anchor"></a>Conversion of Input Environmental Variables</h2>
<p>The values for some input environmental variable data needs to be converted to particular values that are required for the prediction process. These are as follows:</p>
<ul>
<li>NGR converted to latitude and longitude</li>
<li>Calculate mean air temperature and temperature range from latitude and longitude (GB only)</li>
<li>Calculate Mean Substratum Composition</li>
<li>Estimating Discharge Category (if unavailable) from Stream Velocity</li>
<li>Estimating Alkalinity (if unavailable) from Hardness, Calcium or Conductivity. In addition, some EVs then need further conversion</li>
<li>NGR convert many EVs to logarithms</li>
<li>Replace values of some EVs to prevent arithmetical problems, such as division by zero</li>
</ul>
<p>The required conversion rules and some validation rules that need to be applied are described below.</p>
</div>
<div id="deriving-latitude-and-longitude-from-grid-references" class="section level2">
<h2 class="hasAnchor">
<a href="#deriving-latitude-and-longitude-from-grid-references" class="anchor"></a>Deriving Latitude and Longitude from Grid References</h2>
<p>Grid references consists of:</p>
<p>nat_grid_ref = 2 letters for the British National Grid (BNG) or 1 letter for the Irish grid specifying a 100km x 100km grid square</p>
<p>easting = 3 digit Easting within the 100km grid square (to nearest 100m)</p>
<p>northing = 3 digit Northing within the 100km grid square (to nearest 100m)</p>
<p>To derive latitude and longitude, the NGR input by the users is run through <code>getLatLong()</code> in the <code>helper-functions.R</code> file.</p>
<p>This code converts the grid references to Latitude and Longitude WGS84 system. This co-ordinate system is required to calculate Long Term Average Mean Temperature and Range of Air Temperature environmental variables.</p>
<p>The specific function code used within <code>helper-functions.R</code> is as below:</p>
<p><code>getLatLong &lt;- function(nat_grid_ref, easting, northing, coordsys_latlon, area)</code></p>
<p>where:</p>
<p><code>nat_grid_ref</code>, are the grid letter(s), <code>easting</code> and <code>northing</code> from the user input file, <code>coordsys_latlon</code> uses the WGS84 system as described above and <code>area</code> is <code>gb</code> or <code>ni</code>.</p>
</div>
<div id="calculating-mean-and-range-of-air-temperature-from-latitude-and-longitude" class="section level2">
<h2 class="hasAnchor">
<a href="#calculating-mean-and-range-of-air-temperature-from-latitude-and-longitude" class="anchor"></a>Calculating Mean and Range of Air Temperature from Latitude and Longitude</h2>
<p>This conversion process is only applicable to GB model sites.</p>
<p>When converting Latitude and Longitude to Long Term Average Mean Temperature and Range of Air Temperature, RICT2 uses a data file containing previously derived values for Mean air temperature and Air temperature range for points in the centres of 5km interval grid squares. This data file can be found in the inst/ext directory and is called AirTempGrid.</p>
<p>To calculate Long Term Average Mean Temperature and Range of Air Temperature, the Latitude and Longitude previously derived is run through <code>calc_temperatures.R</code> within the prediction support files folder.</p>
<p>The specific function code used within <code>calc_temperatures.R</code> is as below:</p>
<p><code>calculated_temps &lt;- calcTemps(coordinates)</code></p>
<p>where:</p>
<p>coordinates are the eastings and northings (lat, long) calculated values as described in Section 6.1</p>
<pre><code># R version originally written by by C. Laize CEH in early 2012
# Based on FORTRAN PROGRAM TEMPGRID
# For QC and traceability, followed the FORTRAN code as closely as possible; not necessarily best R code
# Converted to calc.temps function by M Dunbar, Environment Agency April 2018

# Modified by T Loveday to avoid errors on east coast, Environment Agency May 2019 
# Modified by T Loveday Environment Agency Mar 2020 to improve look and performance
############################################

#Program to calculate mean temperature and annual temperature range

calc.temps &lt;- test1&lt;-function(coordinates){
# coordinates is a data frame with three columns
# SITE_ID
# EASTING4
# NORTHING4
  
# this function will know about AirTempGrid because it will have been defined in the global environment just
# before the function has been called. This isn't great programming practice, but will do for now.
  
SMEAN&lt;-NULL
SRANGE&lt;-NULL

TempGrid_out&lt;-data.frame()
for (l in c(1:nrow(coordinates))) {#0
if(nchar(coordinates$Site_ID[l])&lt;4) {
  for(z in c(1:(4-nchar(coordinates$Site_ID[l])))){
    coordinates$Site_ID[l]&lt;-paste("0", coordinates$Site_ID[l],sep="")
  }
}

NP&lt;-0
subsetATG1 &lt;- NULL
IGEAST&lt;-coordinates$Easting[l]    #============================================================
                        #remember to change back
IGNORTH&lt;-coordinates$Northing[l]  #============================================================

KE&lt;-IGEAST-25
KN&lt;-IGNORTH-25

#find nearest 5km-point to sw and distances e and n from that
#although this point might be the below the site location as the first four are derived by adding 50 to east and nort

KSQE&lt;-(trunc(KE/50)*50)+25
KSQN&lt;-(trunc(KN/50)*50)+25

IREME&lt;-IGEAST-KSQE
IREMN&lt;-IGNORTH-KSQN

ME1&lt;-KSQE
ME2&lt;-ME1
MN1&lt;-KSQN
MN2&lt;-MN1

#test if at a 5km-point or a vertical or horizontal between
if (IREME==0 &amp; IREMN==0) {#1 site is coincident with a point possible on the grid
        subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1 &amp; Easting &lt;= ME2 &amp; Northing &gt;= MN1 &amp; Northing &lt;= MN2)
    NP&lt;-nrow(subsetATG1) ;SMEAN&lt;-subsetATG1$TEMPM ;SRANGE&lt;-subsetATG1$TEMPR

    if(NP==1){#2
    } else {#2 if the point is not present in the tempgrid file the search is expanded to the surrounding 8 squares 
            subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1 -50 &amp; Easting &lt;= ME2 + 50 &amp; Northing &gt;= MN1 -50 &amp; Northing &lt;= MN2 + 50)
        NP&lt;-nrow(subsetATG1)
        if(NP&gt;3){#3
        } else {#3 if 3 of the 8 points are not present in the tempgrid file the search is expanded to the surrounding 24 squares 
            subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1 -100 &amp; Easting &lt;= ME2 + 100 &amp; Northing &gt;= MN1 -100 &amp; Northing &lt;= MN2 + 100)
            NP&lt;-nrow(subsetATG1)
            if(NP&lt;4){NP&lt;-0} else {}#4
            }#3
        }#2 
} else {#1
        if (IREME==0) {#5 site lies on the N/S line of a point which may or may not be in the temp grid
            subsetATG1 &lt;- subset(AirTempGrid,  Easting == ME1  &amp; Northing &gt;= MN1 &amp; Northing &lt;= MN2 + 50)
            NP&lt;-nrow(subsetATG1)
            if(NP==2){#6
            } else {#6 if either point is absent the search is expanded to E and W to give a potential max no of points of 6
                subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1 -50 &amp; Easting &lt;= ME2 + 50 &amp; Northing &gt;= MN1 &amp; Northing &lt;= MN2 + 50)
                NP&lt;-nrow(subsetATG1)    
                if(NP&gt;3){#7
                } else {#7 if less than 4 of the possible 6 points are present the search is expanded N and S to give a potential max no of points of 12
                    subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1 -50 &amp; Easting &lt;= ME2 + 50 &amp; Northing &gt;= MN1 -50 &amp; Northing &lt;= MN2 + 100)
                    NP&lt;-nrow(subsetATG1)
                    if(NP&lt;4){NP&lt;-0} else {}#8
                    }#7 
                }#6 
        } else {#5
                if (IREMN==0) {#9                   
                    subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1  &amp; Easting &lt;=  ME2 + 50 &amp; Northing &gt;= MN1 &amp; Northing &lt;= MN2)
                    NP&lt;-nrow(subsetATG1)
                    if(NP==2){#10                       
                    } else {#10
                        subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1  &amp; Easting &lt;=  ME2 + 50 &amp; Northing &gt;= MN1 -50 &amp; Northing &lt;= MN2 +50)
                        NP&lt;-nrow(subsetATG1)
                        if(NP&gt;3){#11
                        } else {#11
                        subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1 -50  &amp; Easting &lt;=  ME2 + 100 &amp; Northing &gt;= MN1 -50 &amp; Northing &lt;= MN2 +50)
                        NP&lt;-nrow(subsetATG1)
                        if(NP&lt;4){NP&lt;-0} else {}#12
                            }#11
                        }#10
                } else {#9
                        #must interpolate between 4 values if none of the above is satisfied
                        subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1  &amp; Easting &lt;=  ME2 + 50 &amp; Northing &gt;= MN1 &amp; Northing &lt;= MN2 +50)
                        NP&lt;-nrow(subsetATG1)
                        if(NP&gt;2) {#13
                        } else {#13
                                subsetATG1 &lt;- subset(AirTempGrid,  Easting &gt;= ME1 -50  &amp; Easting &lt;=  ME2 + 100 &amp; Northing &gt;= MN1 -50 &amp; Northing &lt;= MN2 +100)
                                NP&lt;-nrow(subsetATG1)
                                if(NP&lt;4){
                                    NP&lt;-0
                                    } else {}#14    
                            }#13
                    }#9 
            }#5
    }#1
#write.csv(subsetATG1 ,"Subset.csv", row.names = FALSE, append = FALSE)
if(NP==0){
    smean&lt;-0
    srange&lt;-0
    }else{
    if(NP==1){ 
        smean&lt;- subsetATG1$TEMPM
        srange&lt;- subsetATG1$TEMPR
        }else{
        subsetATG1$D&lt;-(subsetATG1$Easting-(KE+25))^2+(subsetATG1$Northing-(KN+25))^2
        ifelse(subsetATG1$D!=0.000000, subsetATG1$DS&lt;-1/subsetATG1$D, subsetATG1$DS&lt;-0.01)
        smean&lt;- sum(subsetATG1$TEMPM/subsetATG1$D)/sum(subsetATG1$DS)
        srange&lt;- sum(subsetATG1$TEMPR/subsetATG1$D)/sum(subsetATG1$DS)
        }
    }
print(paste(coordinates[l,1],NP, smean, srange))
TempGrid_out&lt;-rbind(TempGrid_out, cbind(coordinates[l,], smean, srange))
}#0
TempGrid_out&lt;-as.data.frame(TempGrid_out)
#write.csv(TempGrid_out,"TempGrid.csv", row.names = FALSE, append = TRUE)
}</code></pre>
<p>The temperature grid below is used to obtain mean air temperature and mean air temperature range for RICT predictions. The dots represent points on the existing temperature grid if the site has exactly the same coordinates as the centre point</p>
<p><strong>Key</strong></p>
<p><code>●</code> Available data point<br><code>◎</code> Data point included in the sample<br><code>◌</code> Nearest point on the existing temperature grid to the site</p>
<ol style="list-style-type: decimal">
<li>If the site has exactly the same coordinates as the centre point</li>
</ol>
<p>If the point has exactly the same coordinates as the centre point it samples only the centre point to provide the temperature mean and range if that point exists in the dataset:</p>
<pre><code>● ● ● ● ●  
● ● ● ● ●  
● ● ◎ ● ●  
● ● ● ● ●  
● ● ● ● ● </code></pre>
<p>If the centre point doesn’t exist in the above example then the surrounding 8 points are sampled, if more than 4 of the 8 pts are present within the dataset a value is returned:</p>
<pre><code>● ● ● ● ●   
● ◎ ◎ ◎ ●   
● ◎ ◌ ◌ ◌   
● ◎ ◎ ◌ ◌   
● ● ● ● ●   </code></pre>
<p>if the above condition is not satisfied then the sampling is expanded to include the adjacent points, if at least 5 of the 24 possible points are available a result is returned - if less than 5 no result is returned:</p>
<pre><code>◎ ◎ ◎ ◎ ◎     
◎ ◎ ◎ ◎ ◎   
◎ ◎ ◌ ◌ ◌   
◎ ◎ ◎ ◌ ◌   
◎ ◎ ◎ ◎ ◎   </code></pre>
<ol start="2" style="list-style-type: decimal">
<li>If the site lies exactly on the N/S line of the centre point</li>
</ol>
<p>if the point lies exactly on the N/S line of the centre point then the nearest point and the one above are sampled if both points are present in the dataset:</p>
<pre><code>● ● ● ● ●   
● ● ◎ ● ●   
● ● ◎ ● ●   
● ● ● ● ●   
● ● ● ● ●   </code></pre>
<p>if one of the two points above is not present in the dataset then the two either side are also sampled, if more than three points are present a result is returned:</p>
<pre><code>● ● ● ● ●  
● ◎ ◌ ◎ ●  
● ◎ ◎ ◎ ●  
● ● ● ● ●  
● ● ● ● ●  </code></pre>
<p>if less than 4 of the 6 points above are present in the dataset then the three above and below are also sampled if that at least 4 of the 12 are present a result is returned:</p>
<pre><code>● ◎ ◎ ◎ ●  
● ◎ ◌ ◌ ●  
● ◎ ◎ ◌ ●  
● ◎ ◎ ◎ ●  
● ● ● ● ●  </code></pre>
<ol start="3" style="list-style-type: decimal">
<li>if the site lies exactly on the E/W line of the centre point</li>
</ol>
<p>if the point lies exactly on the E/W line of the centre point then the nearest point and the east of it will be sampled if both points are present in the dataset:</p>
<pre><code>● ● ● ● ●  
● ● ● ● ●  
● ● ◎ ◎ ●  
● ● ● ● ●  
● ● ● ● ●  </code></pre>
<p>if one of the two pointts above are not present in the dataset then the two either side are also sampled, if more than three points are present a result is returned:</p>
<pre><code>● ● ● ● ●  
● ● ◎ ◎ ●  
● ● ◎ ◎ ●  
● ● ◎ ◎ ●  
● ● ● ● ●   </code></pre>
<p>if less than 4 of the 6 points above are present in the dataset then the three east and west are also sampled assuming that at least 4 of the 12 are present:</p>
<pre><code>● ● ● ● ●  
● ◎ ◌ ◌ ◎   
● ◎ ◎ ◌ ◎   
● ◎ ◎ ◎ ◎   
● ● ● ● ●  </code></pre>
<ol start="4" style="list-style-type: decimal">
<li>If none of the above are satisfied - the majority of sites. The site is not coincident with any point or the n/s or e/w line of any point</li>
</ol>
<p>interpolates between four values, 3 of the 4 points must be present to return a value:</p>
<pre><code>● ● ● ● ●  
● ● ◎ ◎ ●  
● ● ◎ ◎ ●  
● ● ● ● ●  
● ● ● ● ●  </code></pre>
<p>if the above is not satisfied then the sampling is expanded to take in 16 points of which 5 or more must be present:</p>
<pre><code>● ◎ ◎ ◎ ◎  
● ◎ ◎ ◌ ◌     
● ◎ ◎ ◌ ◌    
● ◎ ◎ ◎ ◎  
● ● ● ● ●  </code></pre>
</div>
<div id="calculating-mean-substratum-composition" class="section level2">
<h2 class="hasAnchor">
<a href="#calculating-mean-substratum-composition" class="anchor"></a>Calculating Mean Substratum Composition</h2>
<p>MSUBST (in phi units) is derived from the following user-supplied environmental variables from the input file for the river bed substratum composition observed at the sampling site:</p>
<pre><code>BOULDER_COBBLES = percentage cover of Boulders/Cobbles  
PEBBLES_GRAVEL  = percentage cover of Pebbles/Gravel  
*SAND   = percentage cover of sand  
*SILT_CLAY  = percentage cover of silt/clay  </code></pre>
<p>The Algorithm used is:</p>
<pre><code>TOTSUB = BOULDER_COBBLES + PEBBLES_GRAVEL + SAND + SILT_CLAY
MSUBST = ( -7.75*BOULDER_COBBLES - 3.25*PEBBLES_GRAVEL + 2*SAND + 8*SILT_CLAY ) / TOTSUB</code></pre>
<p>The specific function code <code>get_substrate</code> used can be found within helper-functions.R</p>
</div>
<div id="estimating-discharge-category-if-unavailable-from-stream-velocity" class="section level2">
<h2 class="hasAnchor">
<a href="#estimating-discharge-category-if-unavailable-from-stream-velocity" class="anchor"></a>Estimating Discharge Category (if unavailable) from Stream Velocity</h2>
<p>If a value for discharge category (DCH) is not supplied by the user for the test site, it is to be estimated from a measurement of surface water velocity category (VEL) supplied by the user. If neither value is provided then an error will be recorded against the site and prediction and classification should not take place for that site.</p>
<p>The conversion from user-supplied velocity category (VEL) to discharge category (DCH) is done by:</p>
<ol style="list-style-type: decimal">
<li>Converting the velocity category (VEL) to an estimate of some sort of mid- or typical actual velocity</li>
</ol>
<table class="table">
<colgroup>
<col width="28%">
<col width="32%">
<col width="38%">
</colgroup>
<thead><tr class="header">
<th align="left">Velocity category VELC(VEL)</th>
<th align="left">Velocity Category(VEL) (cm.s-1)</th>
<th align="left">Mid-range estimate VELC(VEL) (cm.s-1)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">≤10</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">&gt;10 – 25</td>
<td align="left">17.5</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">&gt;25 – 50</td>
<td align="left">37.5</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">&gt;50 – 100</td>
<td align="left">75</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">&gt;100</td>
<td align="left">150</td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: decimal">
<li><p>Then use the equation <code>RDCH = DEPTH/100 * WIDTH * VELC(VEL)/100</code> to convert the estimated velocity VELC(VEL) into an estimated actual mean discharge RDCH in cumecs</p></li>
<li><p>Finally, assign the estimated discharge RDCH to the appropriate discharge category DCH based on the discharge category upper limits below</p></li>
</ol>
<table class="table">
<thead><tr class="header">
<th align="left">Discharge Category DCH</th>
<th align="left">Mean annual discharge RDCH(m3.s-1 = cumecs)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">&lt; 0.31</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">0.31 - 0.62</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">0.62 - 1.25</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">1.25 - 2.50</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">2.50 - 5.00</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">5.00 - 10.00</td>
</tr>
<tr class="odd">
<td align="left">7</td>
<td align="left">10.00 - 20.0</td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="left">20.00 - 40.0</td>
</tr>
<tr class="odd">
<td align="left">9</td>
<td align="left">40.00 - 80.0</td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="left">&gt;80</td>
</tr>
</tbody>
</table>
<p>The FORTRAN algorithm for estimating DCH from Stream Velocity is:</p>
<pre><code>DATA cdch / 0.31, 0.62, 1.25, 2.5, 5.0, 10.0, 20.0, 40.0, 80.0 /  
CDCH(1) = 0.31  
CDCH(2) = 0.62  
CDCH(3) = 1.25  
CDCH(4) = 2.50  
CDCH(5) = 5.0  
CDCH(6) = 10.0  
CDCH(7) = 20.0  
CDCH(8) = 40.0  
CDCH(9) = 80.0  
  
VELC(1) = 5.0  
VELC(2) = 17.5  
VELC(3) = 37.5  
VELC(1) = 75.0  
VELC(1) = 150.0  
RDCH = DEPTH/100. * WIDTH * VELC(VEL)/100  
K=10  
REPEAT    
DCH=K  
K=K-1  
UNTIL RDCH&gt;CDCH(K)`</code></pre>
<p>The specific function code is <code>get_discharge()</code> used can be found within helper-functions.R.</p>
</div>
<div id="estimating-alkalinity-if-unavailable-from-hardness-calcium-or-conductivity" class="section level2">
<h2 class="hasAnchor">
<a href="#estimating-alkalinity-if-unavailable-from-hardness-calcium-or-conductivity" class="anchor"></a>Estimating Alkalinity (if unavailable) from Hardness, Calcium or Conductivity</h2>
<p>If a value for alkalinity (ALK) is not supplied by the user for the test site, then it is to be assumed that alkalinity is to be estimated from, in order of preference, the user-supplied values for either water hardness (HARD), calcium concentration (CALCIUM) or conductivity (CONDUCT).</p>
<p>If none of these values are provided then an error should be recorded against the site and prediction and classification should not then take place for that site.</p>
<p>The algorithm for estimating Alkalinity from the other values is:</p>
<pre><code>IF HARD is provided THEN  
ALK = 4.677 + 0.6393*HARD  
ELSE  
IF CALCIUM is provided THEN  
ALK = 14.552 + 1.7606*CALCIUM  
ELSE  
IF CONDUCT is provided THEN  
ALK = 0.3201*CONDUCT -8.0593</code></pre>
<p>The specific helper function is <code>get_alkalinity()</code>.</p>
</div>
<div id="transform-environmental-variables-to-logarithm-base-10-form" class="section level2">
<h2 class="hasAnchor">
<a href="#transform-environmental-variables-to-logarithm-base-10-form" class="anchor"></a>Transform Environmental Variables to Logarithm Base 10 Form</h2>
<p>Some environmental predictor variables are used in discriminant functions in a logarithm to base10 transformed form (denoted Log10). They, therefore, need to be converted prior to prediction.</p>
<p>The discriminant functions for the Great Britain (GB) model (Reference end group set 1) use 13 environmental predictor variables (i.e. vN = 13), as detailed below.</p>
<p>The Northern Ireland (NI) model (Reference end group set 2) uses the same set of variables apart from air temperature mean (TEMPM) and air temperature range (TEMPR), which were not available for Northern Ireland and probably would not add discriminatory power within this relatively small geographic region.</p>
<p>For the purposes of specifying the discriminant functions and inputting their coefficients (DFCoeffv,d), RICT2 will have a separate Helperfunctionv1.r folder (within the prediction support files) for the Northern Ireland model experiment.</p>
<p>Some of the environmental predictor variables are used in the discriminant functions in a logarithm to base 10 transformed form (denoted Log10), as detailed below.</p>
<p>Specific functions within the <code>helper-functions.R</code> will do the conversions as described in Sections 6.1 – 6.6 above and will also calculate to log base 10 for any Environmental variables that require Log Base 10 form.</p>
<p>The precise order and form of the environmental variables to be used as Env 1– EnvvN in the discrimination functions equations used to calculate the discriminant function axis scores (DFScore) is as follows:</p>
<table class="table">
<thead><tr class="header">
<th align="left">EV</th>
<th align="left">User input</th>
<th align="left">Environmental predictor variable</th>
<th align="left">Area</th>
<th align="left">Derived</th>
<th align="left">Form used in DFs</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">ENV 3</td>
<td align="left">ALTITUDE</td>
<td align="left">Altitude</td>
<td align="left">gb</td>
<td align="left">input</td>
<td align="left">vld_alt_src_log</td>
</tr>
<tr class="even">
<td align="left">ENV 3</td>
<td align="left">ALTITUDE</td>
<td align="left">Altitude</td>
<td align="left">ni</td>
<td align="left">input</td>
<td align="left">vld_alt_src_log</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">SLOPE</td>
<td align="left">Slope at site</td>
<td align="left">gb</td>
<td align="left">input</td>
<td align="left">vld_slope_log</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">SLOPE</td>
<td align="left">Slope at site</td>
<td align="left">ni</td>
<td align="left">input</td>
<td align="left">vld_slope_log</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">DISCHARGE</td>
<td align="left">Discharge category</td>
<td align="left">gb</td>
<td align="left">input</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">DISCHARGE</td>
<td align="left">Discharge category</td>
<td align="left">ni</td>
<td align="left">input</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">VELOCITY</td>
<td align="left">Velocity</td>
<td align="left">gb</td>
<td align="left">input</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">VELOCITY</td>
<td align="left">Velocity</td>
<td align="left">ni</td>
<td align="left">input</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">ENV 4</td>
<td align="left">DIST_FROM_SOURCE</td>
<td align="left">Distance from Source</td>
<td align="left">gb</td>
<td align="left">input</td>
<td align="left">vld_dist_src_log</td>
</tr>
<tr class="even">
<td align="left">ENV 4</td>
<td align="left">DIST_FROM_SOURCE</td>
<td align="left">Distance from Source</td>
<td align="left">ni</td>
<td align="left">input</td>
<td align="left">vld_dist_src_log</td>
</tr>
<tr class="odd">
<td align="left">ENV 5</td>
<td align="left">MEAN_WIDTH</td>
<td align="left">Stream Width</td>
<td align="left">gb</td>
<td align="left">input</td>
<td align="left">mn_width_log</td>
</tr>
<tr class="even">
<td align="left">ENV 5</td>
<td align="left">MEAN_WIDTH</td>
<td align="left">Stream Width</td>
<td align="left">ni</td>
<td align="left">input</td>
<td align="left">mn_width_log</td>
</tr>
<tr class="odd">
<td align="left">ENV 6</td>
<td align="left">MEAN_DEPTH</td>
<td align="left">Stream Depth</td>
<td align="left">gb</td>
<td align="left">input</td>
<td align="left">mn_depth_log</td>
</tr>
<tr class="even">
<td align="left">ENV 6</td>
<td align="left">MEAN_DEPTH</td>
<td align="left">Stream Depth</td>
<td align="left">ni</td>
<td align="left">input</td>
<td align="left">mn_depth_log</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">MSUBST</td>
<td align="left">Mean substratum</td>
<td align="left">gb</td>
<td align="left">calculated</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">MSUBST</td>
<td align="left">Mean substratum</td>
<td align="left">ni</td>
<td align="left">calculated</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">HARDNESS</td>
<td align="left">Mean substratum</td>
<td align="left">all</td>
<td align="left">input</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">CALCIUM</td>
<td align="left">Calcium concentration</td>
<td align="left">all</td>
<td align="left">input</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">ENV 9</td>
<td align="left">ALKALINITY</td>
<td align="left">Alkalinity as CaCO3</td>
<td align="left">gb</td>
<td align="left">input</td>
<td align="left">vld_alkal_log</td>
</tr>
<tr class="even">
<td align="left">ENV 9</td>
<td align="left">ALKALINITY</td>
<td align="left">Alkalinity as CaCO3</td>
<td align="left">ni</td>
<td align="left">input</td>
<td align="left">vld_alkal_log</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">TOTSUB</td>
<td align="left"></td>
<td align="left">all</td>
<td align="left">calculated</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<ul>
<li>Alkalinity is involved in the discriminant functions in both untransformed form (as Env9) and in log transformed form (as Env) to represent its non-linear impact on the biota.</li>
</ul>
<p>This table also shows which EVs are supplied by the user in the input file and which EVs are internally derived by RICT2 conversions.</p>
</div>
<div id="validation-of-derived-environmental-variables" class="section level2">
<h2 class="hasAnchor">
<a href="#validation-of-derived-environmental-variables" class="anchor"></a>Validation of Derived Environmental Variables</h2>
<p>Whenever the value of an Environmental variable is derived from any conversion applied, it needs to be validated against the various max/min values. There are two distinct max/min values; Fail and Warn and the required validation is as detailed previously in section 5.</p>
<p>Once all the conversion processing has been carried out, then this should result in a value being present for every required Environmental variable. This complete set of Environmental variables is called the Predictive Environmental Variables (PEVS).</p>
</div>
</div>
<div id="prediction-1" class="section level1">
<h1 class="hasAnchor">
<a href="#prediction-1" class="anchor"></a>Prediction</h1>
<div id="prediction-process" class="section level2">
<h2 class="hasAnchor">
<a href="#prediction-process" class="anchor"></a>Prediction Process</h2>
<p>The prediction functionality involves four distinct steps:</p>
<ol style="list-style-type: lower-alpha">
<li>determine the probability of end group membership<br>
</li>
<li>determine Environmental Suitability<br>
</li>
<li>based on a), determine the predicted index values for the indices relevant to the run<br>
</li>
<li>based on a), determine the predicted taxa to be present at the site</li>
</ol>
<p>The most complex part of this is a), which involves the use of multiple discriminant analysis and specialised statistical techniques (e.g. Mahanalobis Distance).</p>
<p>It needs to be carried out for every set of site data applicable to the run (a site may be present more than once where more than one years’ worth of environmental data has been provided).</p>
<p>The flow diagram below summarises the prediction process and calculations (including the data input, validation, conversion and transform steps described above) as well as identifying the relevant section for further information from the WFD72C final report:</p>
<p><img src="images/rict-prediction.png" width="585" height="444"></p>
</div>
<div id="prediction-overview" class="section level2">
<h2 class="hasAnchor">
<a href="#prediction-overview" class="anchor"></a>Prediction Overview</h2>
<p>The probability of a site belonging to an End Group is determined by the similarity of its Environmental Variables (EVs) to those of the relevant End Group.</p>
<p>Due to the multivariate nature of the environmental variable data, Multiple Discriminant Analysis (MDA) is used to turn the environmental variable data into a format that can be used to discriminate between the end groups.</p>
<p>MDA depends on multiple Discriminant Functions (DF). A Discriminant Function has the general format:-</p>
<pre><code>Z = constant + c1EV1 + c2EV2 + c3EV3 + ... + cnEVn</code></pre>
<p>where Z is the Discriminant Score (DS) for that particular discriminant function, c1…cn are the coefficients of that discriminant function and EV1…EVn are the values of the environmental variables.</p>
<p>A DF is a linear combination of the EVs and the coefficients, which maximises the separation in data space of the end groups. In other words, if the discriminant function was solved for the mean values of the environmental variables of each end group and the results plotted on a line, the value from the solved formula for each end group would be as far apart from its nearest neighbour as could be achieved by using the available environmental variables to separate the end groups</p>
</div>
<div id="environmental-variables" class="section level2">
<h2 class="hasAnchor">
<a href="#environmental-variables" class="anchor"></a>Environmental Variables</h2>
<p>The values of the EVs relevant to the prediction run will have been determined during the acceptance, validation and subsequent conversion processing of the input data as described in section 5 and 6 of this document. These are referred to in the algorithm below as EnvvN.</p>
</div>
<div id="discriminant-functions-dfs-and-the-coefficients" class="section level2">
<h2 class="hasAnchor">
<a href="#discriminant-functions-dfs-and-the-coefficients" class="anchor"></a>Discriminant Functions (DFs) and the Coefficients</h2>
<p>The RIVPACS model used will determine the DFs that have to be run. For the GB model 1 with 13 EVs the DFs values can be found in the inst/ext folder for GB in a file called DFCOEFF_GB685.</p>
<p>For the GB model 44 with 17 EVs the DFs values can be found in the prediction support files folder for GB in a file called <code>discrimant-function-coefficients-model-44.csv</code> - see section 12 for additional Model 44 information.</p>
<p>For the NI model with 11 EVs, the DFs values can be found in the prediction support files folder for Northern Ireland in a file called <code>DFCOEFF_NI</code></p>
<p>These are separate occurrences of DF. Each of these has a single ‘constant’ and, for each component EV, a co-efficient that is to be applied to the EV value. The coefficients are referred to in the algorithm below as DFCoef.</p>
</div>
<div id="calculate-the-discriminant-function-scores" class="section level2">
<h2 class="hasAnchor">
<a href="#calculate-the-discriminant-function-scores" class="anchor"></a>Calculate the Discriminant Function Scores</h2>
<p>(Step 4 in diagram above)</p>
<p>The functions that RICT2 uses for the calculations in the steps below (steps 4 - 8) can be found in the prediction-functions.R file. The algorithms and definitions provided below are copied from WFD72C and have been used to create the functions.</p>
<p>For each DF, the Discriminant Score needs to be calculated as follows:</p>
<pre><code>DFScored = DFCoef1,d * Env1 + … + DFCoefvN,d * EnvvN; for d = 1. … dN</code></pre>
<p>Definitions – these have been copied from WFD72C:</p>
<pre><code>v   = id of current environmental predictor variable 
vN  = number of environmental predictor variables
d   = id of current discriminant function axis
dN  =  number of discriminant function axes in current Reference end group set
DFCoefv,d   = discriminant function coefficient for predictor variable v on discriminant function d obtained from the values in the DFCOEFF_GB685 file for Great Britain, DFCOEFF_NI file for Northern Ireland or discrimant-function-coefficients-model-44.csv for model 44 which can be found within the prediction support files.
Envv        = value of environmental predictor variable v for the current test site
DFScored    = discriminant function score on axis d for the current test site </code></pre>
</div>
<div id="calculate-mahanalobis-distance" class="section level2">
<h2 class="hasAnchor">
<a href="#calculate-mahanalobis-distance" class="anchor"></a>Calculate Mahanalobis Distance</h2>
<p>(Step 5 in diagram above)</p>
<p>For a particular End Group g, the probability of End Group Membership is calculated as follows:</p>
<ul>
<li>Calculate Mahanalobis distance (MahDistg) of test site from each End Group</li>
</ul>
<pre><code>MahDistg = (DFScore1 - DFMeang,1)2 + ... + (DFScoredN - DFMeang,dN )2 ; for g = 1,...,gN</code></pre>
<p>Definitions – these have been copied from WFD72C:</p>
<pre><code>g   = id of current end group (set ID: 1 = GB, 2 =NI)
gN  = number of end groups in current Reference end group set
NRefg   = number of reference sites in end group g (
DFMeang,d   = mean discriminant function score of end group g on axis d
Obtained from the ‘target’ values in the DFMEAN_GB685 file forObtained from the table x-103-end-group-means.csv which is within the inst/ext folder) Great Britain, DFMEAN_NI file for Northern Ireland or end-group-means-discriminant-scores-model-44.csv for Model 44.
MahDistg    = Mahalanobis distance of test site from end group g</code></pre>
</div>
<div id="use-mahanalobis-distance-to-determine-probability-of-end-group-membership" class="section level2">
<h2 class="hasAnchor">
<a href="#use-mahanalobis-distance-to-determine-probability-of-end-group-membership" class="anchor"></a>Use Mahanalobis Distance to Determine Probability of End Group Membership</h2>
<p>(Step 6 in diagram above)</p>
<ul>
<li>Calculate the PDistg for each End Group</li>
</ul>
<pre><code>PDistg  = NRef g * EXP(-MahDist g/2)</code></pre>
<p>where NRef g = the number of reference sites in the End Group (from the End Group Reference Data table) and EXP is the natural exponential function</p>
<ul>
<li>Calculate the PDistTot</li>
</ul>
<pre><code>PDistTot = PDist 1 to PDist gN</code></pre>
<p>where gN is the number of end groups in the relevant end group set</p>
<ul>
<li>Calculate the Probability of End Group Membership (Probg)</li>
</ul>
<pre><code>Probg = PDistg / PDistTot</code></pre>
<p>where Probg is the Probability test site belongs to end group g</p>
<p>At the end of this process we end up with a set of probabilities of End Group Membership, one for each End Group. These are referred to below as Prob1 to Probn.</p>
</div>
<div id="determine-environmental-suitability-of-the-test-site-for-prediction" class="section level2">
<h2 class="hasAnchor">
<a href="#determine-environmental-suitability-of-the-test-site-for-prediction" class="anchor"></a>Determine Environmental Suitability of the Test Site for Prediction</h2>
<p>(Step 7 in diagram above)</p>
<p>In certain cases it may be calculated that there is a very low probability of the site being in any of the end groups based on the data provided.</p>
<p>In order to highlight this to the user, a calculation is required to allocate an Environmental Suitability code to the site data indicating the probability the site belongs to any end group. The potential codes are:</p>
<ul>
<li>1 OK</li>
<li>2 &lt; 5%</li>
<li>3 &lt; 2%</li>
<li>4 &lt; 1%</li>
<li>5 &lt; 0.1%</li>
</ul>
<p>The required calculation uses the Chi-square values (CQ1 to CQ4) which vary per End Group Set as below:</p>
<table class="table">
<thead><tr class="header">
<th align="left">End Group set (ID)</th>
<th align="left">CQ1</th>
<th align="left">CQ2</th>
<th align="left">CQ3</th>
<th align="left">CQ4</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">RIVPACS IV GB (set 1)</td>
<td align="left">21.02606</td>
<td align="left">24.05393</td>
<td align="left">26.21696</td>
<td align="left">32.90923</td>
</tr>
<tr class="even">
<td align="left">RIVPACS IV NI (set 2)</td>
<td align="left">18.307</td>
<td align="left">21.1608</td>
<td align="left">23.2093</td>
<td align="left">29.5883</td>
</tr>
</tbody>
</table>
<p>PredictionfunctionsV1 (within the prediction support files folder) has a function called getSuitabilityCode() which will do this calculation.</p>
<p>The detailed calculation is as follows:</p>
<ul>
<li>Calculate the minimum Mahanalobis distance (MahDistmin)</li>
</ul>
<pre><code>MahDistmin = minimum of (MahDist1,….,MahDistn)</code></pre>
<ul>
<li>Calculate the Environmental Suitability Code and Suitability text</li>
</ul>
<p>If the MahDistmin &lt; value for CQ1 then Suitability Code = 1 and suitability text is &gt;5%</p>
<p>If the MahDistmin &gt;= value for CQ1 and &lt; value for CQ2 then Suitability Code = 2 and suitability text is &lt;5%</p>
<p>If the MahDistmin &gt;= value for CQ2 and &lt; value for CQ3 then Suitability Code = 3 and suitability text is &lt;2%</p>
<p>If the MahDistmin &gt;= value for CQ3 and &lt; value for CQ4 then Suitability Code = 4 and suitability text is &lt;1%</p>
<p>If the MahDistmin &gt;= value for CQ4 then Suitability Code = 5 and suitability text is &lt;0.1%</p>
<p>The output file will provide the user with the Suitability Code and suitability text. The Suitability text gives the user information and warnings about the suitability code calculated.</p>
</div>
<div id="determine-the-predicted-values-of-indices" class="section level2">
<h2 class="hasAnchor">
<a href="#determine-the-predicted-values-of-indices" class="anchor"></a>Determine the Predicted Values of Indices</h2>
<p>(Step 8 in diagram above)</p>
<p>The indices that require to be processed will be identified from the project experiment settings. For the initial release of RICT2 this will be for WHPT ASPT and WHPT NTAXA sets which are the indices required for the WFD classification. However, for Prediction, all 80 indices (which includes WHPT ASPT and WHPT NTAXA sets), will be used at this point and for Prediction only.</p>
<p><code>prediction-functions.R</code> contains the following functions which will do this calculation:</p>
<p><code>getSeasonIndexScores &lt;- function (data_to_bindTo, season_to_run, index_id, end_group_IndexDFrame, model)</code></p>
<p>and the: end_group_IndexDFrame uses the <code>x-103-end-group-means.csv</code> file</p>
<p>Algorithm: (copied from WFD72C)</p>
<pre><code>ExpIDXi     = Prob1 * IDXmeani,s,1, + ... + ProbgN * IDXmeani,s,gN</code></pre>
<p>Definitions: (these have been copied from WFD72C)</p>
<pre><code>g   = id of current end group
gN  = number of end groups in current Reference end group set (set: 1 = GB, 2 =NI)
Probg   = Probability test site belongs to end group g
i   = id of current biological index
iN  = total number of biological indices
s   = id of selected season(s) combination (referred to as ‘season s’); (1 = spring, 2 = summer, 3 = autumn, 4 = pooled spring + summer, 5 = pooled spring + autumn, 6 = pooled summer + autumn, 7 = all three seasons pooled – only 1, 2 and 3 are used in RICT 2) 
IDXMeani,s,g    = Mean value of index i for season s for reference sites in end group g 
ExpIDXi     = Expected value of index i for selected season s for current test site </code></pre>
<p>Internally-supplied Data files:</p>
<p>A separate file called <code>x-103-end-group-means.csv</code> will be provides the values for:</p>
<pre><code>IDXMeani,s,g    = Mean value of index i for season s for reference sites in end group g  </code></pre>
</div>
<div id="completion-and-outputs-of-prediction-processing" class="section level2">
<h2 class="hasAnchor">
<a href="#completion-and-outputs-of-prediction-processing" class="anchor"></a>Completion and Outputs of Prediction Processing</h2>
<p>Once the prediction processing has been completed, the following data has been calculated for each occurrence of site data:</p>
<ul>
<li>Probabilities of End Group Membership</li>
<li>Expected Index Values</li>
<li>Predicted Taxa occurrence details</li>
</ul>
<p>The expected index data is then passed to the classification process.</p>
</div>
</div>
<div id="all-index-prediction" class="section level1">
<h1 class="hasAnchor">
<a href="#all-index-prediction" class="anchor"></a>All index prediction</h1>
<p>This is a modification of the prediction undertaken in the predict and classify experiments. It provides predictions for a wide range of indices.</p>
<p>However, it uses a different end group means data file derived from the RIVPACS database.</p>
<p>The all indices output file will only show the output for prediction for the 80 indices.</p>
<p>The biotic indices included in all index prediction are listed in Appendix B2.</p>
</div>
<div id="taxa-prediction" class="section level1">
<h1 class="hasAnchor">
<a href="#taxa-prediction" class="anchor"></a>Taxa Prediction</h1>
<p>Although not required for status classification, an important feature of RIVPACS that is included in RICT is to be able to predict the taxa expected to be present at the site. For each taxon, the prediction provides:</p>
<ul>
<li>Expected probability of occurrence.</li>
<li>Expected log abundance category.</li>
<li>Expected numerical abundance.</li>
</ul>
<p>The steps involved are described below.</p>
<div id="identify-the-relevant-sites-for-the-run" class="section level2">
<h2 class="hasAnchor">
<a href="#identify-the-relevant-sites-for-the-run" class="anchor"></a>Identify the Relevant sites for the run</h2>
<p>Because of a potentially overwhelming amount of data in the output files, the user must specify which sites included in the input file the prediction is to be carried out. This additional step is undertaken using the manual data entry, explained below.</p>
<p>Notes from write up with Maybin (March 2020):</p>
<p>The following images illustrate the process flow and data requirements for the experiment to be run. The data inputs and support files are different for the GB and NI experiments.</p>
<p>Click on Enter Data Manually</p>
<p>At this point, you choose which sites to run, this is in a .csv format.</p>
<p>Leave the HasHeader box unchecked, if checked it will have a header file.</p>
<p>The data fields are the sites you choose to run for the experiment.</p>
<p>Note, the GB model has no restrictions when it comes to the number of sites that can be run in the experiment, however, the NI model is restricted to a maximum of two sites that can be run for each experiment. Therefore, it is suggested that only two sites are run for the GB model at any one time for it to work effectively. If you want to run all the sites for the GB model you need to put a 0 in the data line.</p>
<p>Example: GB – 1,2 2,3 3,5 4,7 etc., however, for NI only two sites can be run at one time, 1,2 and 3,10 or 2,7 and 3,4 in whichever sequential order you choose.</p>
<p>Figure 1 Example data entered to indicate two sites in the data input file selected for taxon prediction.</p>
</div>
<div id="methods-and-algorithms-to-predict-expected-values-for-each-taxon" class="section level2">
<h2 class="hasAnchor">
<a href="#methods-and-algorithms-to-predict-expected-values-for-each-taxon" class="anchor"></a>Methods and Algorithms to predict Expected values for each taxon</h2>
<p>From Ralph Clarke 30/01/20</p>
<div id="taxon-prediction-data-file" class="section level3">
<h3 class="hasAnchor">
<a href="#taxon-prediction-data-file" class="anchor"></a>Taxon prediction data file</h3>
<p>All of the required taxon prediction data was supplied by John Davy-Bowker in a single file derived from the RIVPACS Reference Database: TAXA_AB_APR_PRAB.csv</p>
<p>This file contains the following 18 columns:</p>
<pre><code>1. Model                1 = GB, 2 = NI
2. End_Group      1-43 for GB, 1-11 for NI
3. TL                   Taxonomic Level: TL1, TL2, TL3, TL4, TL5
4. Season_Code:     1 = spring, 2 = summer, 3 = autumn

The next 6 columns (5-10) should all be stored as Text columns (even those which appear numeric because they need to retain their leading zeroes.

5. Maitland_Code
6. Maitland_Name
7. Furse_Code
8. Furse_Name
9. NBN_Code
10. NBN_Name

The final 8 columns (11-18) are the 8 parameters whose expected values for any test site we wish to calculate for each taxon at each taxonomic level in each season
  
11. Average_Numerical_Abundance
12. Average_Log10_Abundance
13. Prob_Occurrence
14. Prob_Log1
15. Prob_Log2
16. Prob_Log3
17. Prob_Log4
18. Prob_Log5</code></pre>
<p>Note: For the GB model, at any one taxonomic level (TL1 – TL5) and particular season (1-3), any particular taxon at that level only occurs as a row in this input file if it occurred (i.e. has at least one positive taxonomic parameter value) in at least one of the GB RIVPACS IV reference site End-groups. Similarly for taxa in the NI model. Thus the taxa listed (i.e. given) rows varies slightly between seasons because not all taxa were found in every seasons in at least one of the RIVPACS IV model reference sites.</p>
<ul>
<li>TL1 = BMWP taxa</li>
<li>TL2 = WHPT taxa</li>
<li>TL3 = all RIVPACS families</li>
<li>TL4 = all RIVPACS species</li>
<li>TL5 = mixed taxon level</li>
</ul>
<p>Season 1 = spring, 2 = summer, 3 = autumn.</p>
</div>
<div id="algorithm-to-calculate-expected-values-of-the-8-parameters-for-a-gb-test-site" class="section level3">
<h3 class="hasAnchor">
<a href="#algorithm-to-calculate-expected-values-of-the-8-parameters-for-a-gb-test-site" class="anchor"></a>Algorithm to calculate Expected values of the 8 parameters for a GB test site</h3>
<p>End-group means of the 8 parameters to be predicted are supplied in columns 11-18 of the above taxon prediction data file.</p>
<p>When working on the GB model, you first need to subset the data in the taxon prediction file to eliminate the rows for NI (Model =2).</p>
<p>Assuming the RICT software has already read the test site’s environmental input data and calculated the probabilities (P1 , P2 , … P43) of the test site belonging to each of the 43 GB Model End-groups, for any particular taxa K at taxonomic level L in season S, its predicted expected value (ExpJKLS) of Taxonomic parameter J for that season is given by:</p>
<pre><code>EJKLS = P1 x MJKLS(1) + P2 x MJKLS(2) + … + P43 x MJKLS(43)</code></pre>
<p>Where MJKLS(i) = supplied End-group mean of taxonomic parameter J of taxa K at taxonomic level L in season S.</p>
<p>In a mathematical sense that’s it and it appears easy. However, in practice it is not easy, not only because of the vast number of taxa, taxonomic level, end-group and season combinations for which Expected values are required, but also because the number of taxa included in the input file varies between seasons.</p>
</div>
<div id="computing-trick-to-calculate-all-taxonomic-expected-values-for-a-test-site" class="section level3">
<h3 class="hasAnchor">
<a href="#computing-trick-to-calculate-all-taxonomic-expected-values-for-a-test-site" class="anchor"></a>Computing trick to calculate all taxonomic expected values for a test site</h3>
<p>The following computing trick calculates the expected values of taxonomic parameters for all taxa at all levels in all seasons in one step.</p>
<p>If (P1 , P2 , … P43) denote the probabilities of the current test site belonging to each of the 43 GB Model End-groups, then:</p>
<ol style="list-style-type: lower-roman">
<li><p>Copy column 2 (‘End_Group’) to a new column ‘End_Group_Prob’</p></li>
<li><p>Use a software coding (translation) function to recode the new ‘End_Group_Prob’ column so that : 1 becomes P1 , 2 becomes P2, … , 43 becomes P43</p></li>
<li><p>For any particular taxonomic parameter J (denoted here ParamJ and supplied in one of columns 11-18), calculate new column ParamJ_Prob as:</p></li>
</ol>
<p><code>ParamJ_Prob = End_Group_Prob  x ParamJ</code></p>
<ol start="4" style="list-style-type: lower-roman">
<li><p>Use a software multi-way table function using columns (4, 3, 7, 5, 6, 8, 9, 10,) in that order) as multi-way table classifiers) and then sum the column ‘ParamJ_Prob’ across all 43 ‘End-groups’ which it will do by default in any sum function as ‘End_Group’ is not one of the table classifiers.</p></li>
<li><p>You actually want to use a multi-way table function which creates a new output set of columns with one new column for each table classifier and one for the sum across end-groups of the column ‘ParamJ_Prob’</p></li>
<li><p>In fact, if you can do this for one of 8 taxonomic parameters, you could probably do it for all 8 parameters at one step, having first derived the 8 intermediary columns: Param1_Prob, Param2_Prob,… , Param8_Prob</p></li>
</ol>
<p>The order of multi-way table classifying columns that I specified above, namely (4, 3, 7, 5, 6, 8, 9, 10) will ensure that new columns of Expected taxonomic parameters will have classifier columns sorted first on Season, then Taxonomic Level, then Furse code, and finally all of the other alternative taxonomic codes for a taxa. I have suggested using ‘Furse_Code’ as the first (and primary individual taxonomic code) as I think it is unique and always available. It will also make it easier to compare with Ralph’s independent test code.</p>
<p>In summary, this should lead to an output file of 18 columns, akin to those in the input file, but where the values in output file columns 11-18 are now the predicted Expected values for the 8 taxonomic parameters for each combination of season, taxonomic level and taxa code as specified in output file columns 1-10.</p>
<p>This procedure could be done for each test site in turn. The 18 output columns for each site could be stacked so that there is one additional output column denoting ‘SiteName’.</p>
<p>The single output file of columns can now be re-sorted externally by the User or use to subset by SiteName, Season, Taxonomic Level and/or Tax code, as required. For example, to just get predictions of taxonomic parameters for taxa at taxonomic level TL1 (BMWP family level), you just subset the 18 output columns by column TL= TL2.</p>
<p>If the user wishes to only view the prediction results, a csv output will be generated in the project experiment which can be downloaded and used for reports.</p>
</div>
<div id="taxon-prediction-output" class="section level3">
<h3 class="hasAnchor">
<a href="#taxon-prediction-output" class="anchor"></a>Taxon prediction Output</h3>
<p>Taxon prediction output includes a row for each taxon predicted. For each site, expect about 3500 rows of data. The first block of rows will be for the first site selected and below it the results for the second site. Each row includes the same columns as the taxon prediction data file, together with siteName. Sections below are based on notes from write up with Maybin (March 2020):</p>
</div>
</div>
<div id="data-input-files-in-addition-to-the-taxon-prediction-data-file" class="section level2">
<h2 class="hasAnchor">
<a href="#data-input-files-in-addition-to-the-taxon-prediction-data-file" class="anchor"></a>Data Input files in addition to the taxon prediction data file</h2>
<div id="gb-ni" class="section level3">
<h3 class="hasAnchor">
<a href="#gb-ni" class="anchor"></a>GB &amp; NI</h3>
<ul>
<li>New Input File <code>wValidation wTestData.csv</code>
</li>
<li><code>prediction-functions.R</code></li>
<li>
<code>helper-functions.R</code> – contains all the functions used to run the experiment</li>
</ul>
</div>
</div>
<div id="execute-r-script" class="section level2">
<h2 class="hasAnchor">
<a href="#execute-r-script" class="anchor"></a>Execute R Script</h2>
<p><strong>(Update this section - TF)</strong> Line 350 – this is the same as previous predictions but for taxa prediction we need to find each site’s EndGroup, it uses columns 15:57 for GB and 13:23 for NI. Two functions are used: Function1 EndGroup Probability replacement, gets EndGroup and replaces it with the Probability (GB - columns 15:57 and NI columns 13:23).</p>
<p>Line 366 – an important file as it looks at the taxonomic info from the TAXA_AB_APR_PRAB.csv about the model to be used in the prediction. EndGroup found are used with this file to compute predictions.</p>
<p>Line 371/372 – shows which model is being used for the experiment (GB or NI)</p>
<p>Line 378/396 – this goes through each site and processes each site to do the predictions. The second function, Function2, does the computation of all the columns – it computes the site and adds it to the list of all sites, and repeats this function until all the sites have been computed.</p>
</div>
</div>
<div id="classification-1" class="section level1">
<h1 class="hasAnchor">
<a href="#classification-1" class="anchor"></a>Classification</h1>
<div id="classification-process-summary" class="section level2">
<h2 class="hasAnchor">
<a href="#classification-process-summary" class="anchor"></a>Classification Process Summary</h2>
<p>The flow diagram below summarises the classification process and calculations as well as identifying the relevant section for further information from the WFD72C final report and other sources of information:</p>
<p><img src="images/rict-classification.png" width="593" height="443"></p>
<p>Note that the blue boxes indicate processes that are simulated.</p>
</div>
<div id="classification-overview" class="section level2">
<h2 class="hasAnchor">
<a href="#classification-overview" class="anchor"></a>Classification overview</h2>
<p>For every site in the experiment, the input to the classification process consists of Observed and Expected Index Values for the ‘current year’ for each applicable index.</p>
<p>Multiyear classification will include Observed and Expected Index Values for up to two previous years for each applicable index.</p>
<p>The indices that need to be classified will be relevant to the project experiment. For the WFD classification default experiment, RICT2 will use TL2 WHPT Abundance weighted with distinct taxa for ASPT and NTAXA indices.</p>
<p>Any functions that RICT2 uses for the calculations described in the steps below (steps 1 - 13), can be found in the ClassificationfunctionsV2 within the classification support files folder. The algorithms and definitions provided below are copied from WFD72C plus other sources and have been used to create the functions.</p>
</div>
<div id="expected-values-calculated-by-the-prediction-programme" class="section level2">
<h2 class="hasAnchor">
<a href="#expected-values-calculated-by-the-prediction-programme" class="anchor"></a>Expected Values calculated by the Prediction programme</h2>
<p>(Step 1 in process diagram above and Section 7)</p>
<p>This is the main result from RIVPACS prediction (Section 7), based on environmental variable data input by the user. It is the prediction of the value of the index expected at the site if it was in the best quality available for that type of site, based on samples collected from best available reference sites.</p>
</div>
<div id="adjust-expected-values-to-standardise-against-the-highgood-boundary" class="section level2">
<h2 class="hasAnchor">
<a href="#adjust-expected-values-to-standardise-against-the-highgood-boundary" class="anchor"></a>Adjust Expected Values to Standardise against the High/Good Boundary</h2>
<p>(Step 2 in process diagram above)</p>
<p>The aim of this step is to standardise the raw predictions so that they relate to the same environmental quality (the high/good boundary quality) using algorithms first developed in WFD72b. This step is necessary to take account of variation in the environmental quality of RIVPACS reference sites.</p>
<p>There are a number of processes involved in this step as described below:</p>
<ul>
<li><p>The <code>computeScoreProportions()</code> function within the prediction support files folder is used to calculate proportions (Qij) for each end group using a CSV file (also within the prediction support files folder) called EndGrp_AssessScores.</p></li>
<li><p>The <code>getWeighted_proportion_Rj()</code> function within the prediction support files folder is used to calculate weighted proportions (Rj) using the probabilities from prediction process by multiplying with the Qij proportions.</p></li>
<li><p>The <code>compute_RjAj()</code> function within the prediction support files folder is used to calculate RjAj by multiplying the weighted proportions by the adjustment factors. See below for details regarding the adjustment factors.</p></li>
<li><p>Finally, the RjAj value is used to divide by for all the predictions (NTAXA and ASPT) to get the adjusted expected value (ExpIDXadj,i) for each site and each index.</p></li>
</ul>
<p>The reference adjustment values referred to above are default values for the WFD classification experiment and can be found in adjustParams_ntaxa_aspt csv file within the classification support files folder.</p>
<p>This supporting data table csv file contains the number of reference sites by Biologist assessment score (1-5) for each End Group together with the five adjustment factors (Q1, Q2, Q3, Q4, Q5) for each index.</p>
<p>The source for this csv file is based on the Table 6 from the Testing RICT2 predictions and classifications draft report 2018 which is as below:</p>
<table class="table">
<thead><tr class="header">
<th align="left">Index</th>
<th align="left">WHPT NTAXA</th>
<th align="left">WHPT ASPT</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Q1</td>
<td align="left">1</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">Q2</td>
<td align="left">1</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">Q3</td>
<td align="left">1</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">Q4</td>
<td align="left">0.967</td>
<td align="left">0.977</td>
</tr>
<tr class="odd">
<td align="left">Q5</td>
<td align="left">0.926</td>
<td align="left">0.945</td>
</tr>
</tbody>
</table>
<p>Table 1. Adjustment factors for reference site quality (Q1, Q2, Q3, Q4, Q5) for abundance-weighted WHPT NTAXA and WHPT ASPT</p>
<p>However, further work has been done which has resulted in slightly different values for these adjustment factors which are reflected in the <code>adjustParams_ntaxa_aspt.csv</code> file used by RICT2, It is expected that the Testing RICT2 predictions and classifications draft report 2018 will be shortly updated to include a Table 7 to show these changes.</p>
<p>There is one set of adjustment factors for each index. Within current RICT2, adjustment factors for WHPT NTAXA and WHPT ASPT have been calculated for the default WFD experiment. If a user wants to try a different value then they will need to amend and create their own experiment.</p>
</div>
<div id="eqr-conversion-factor" class="section level2">
<h2 class="hasAnchor">
<a href="#eqr-conversion-factor" class="anchor"></a>EQR Conversion Factor</h2>
<p>(Step 3 in process diagram above)</p>
<p>This is the conversion factor used to convert the adjusted predictions that relate to high/good boundary quality to reference values that relate to reference condition, which is somewhere in high status (reference values are the average value of the metric at reference sites in reference condition = high status)</p>
<p>Each index has a different conversion factor, based on the average value of the index at all RIVPACS Reference Sites divided by the value at RIVPACS reference sites that are in WFD high status (reflected in Biologists’ Assessment values for each reference site).</p>
<p>For the default WFD classification in RICT2 the conversion factor value will be (as copied from Section 5.5 of the Testing RICT2 predictions and classifications draft report 2018):</p>
<ul>
<li>1.0049 for WHPT NTAXA</li>
<li>0.9921 for WHPT ASPT</li>
</ul>
</div>
<div id="convert-adjusted-expected-to-reference-value" class="section level2">
<h2 class="hasAnchor">
<a href="#convert-adjusted-expected-to-reference-value" class="anchor"></a>Convert adjusted expected to reference value</h2>
<p>(Step 4 in process diagram above)</p>
<p>The aim of this step is to convert the predictions from high/good boundary to reference values, which is somewhere in high status (actually the average value of the index at reference sites in high status), by applying the conversion factor.</p>
<p>The conversion factor is applied to the adjusted expected value to give an expected reference value which will be used to calculate the EQRs expected by the Water Framework Directive. Specifically, ExpIDXRef,i is calculated as:</p>
<pre><code>ExpIDXRef,i = ExpIDXAdj,i / K</code></pre>
<p>Where:</p>
<pre><code>ExpIDXAdj,i = the adjusted expected value which is calculated as described in section 8.2 above.
K = WFD conversion factor (i.e. WHPT NTAXA: K = 1.0049, and WHPT ASPT K = 0.9921 as described in section 8.3 above.
IDX = do this for each Index, i.e. for WHPT NTAXA and WHPT ASPT
i = do this for each specific site</code></pre>
<p>This avoids the need for the intermediary step of calculating and referring to EQI (Environmental Quality Indices) values (which are calculated as EQI = Obs / ExpAdj) and means that the site classifications can use the published class limits for index EQR values directly.</p>
<p>This calculation is done directly within RICT2 code and not via any function.</p>
</div>
<div id="simulate-uncertainty-in-expected" class="section level2">
<h2 class="hasAnchor">
<a href="#simulate-uncertainty-in-expected" class="anchor"></a>Simulate uncertainty in expected</h2>
<p>(Step 5 in process diagram above)</p>
<p>The aim of this step is to take account of error in measurement of environmental variables used to predict the reference values.</p>
<p>It should be noted that the “ +eir “ shown in the algorithm in the process step above is a summary of the algorithm values of ZExpir * SDExpi / √(NExpyear) as described in further detail below. It is the error term used to adjust the expected value.</p>
<p>The simulation of uncertainty in ExpRef is obtained using the algorithms in Section 6.4 of the Clarke &amp; Davy-Bowker WHPT indices RICT2 Report of March 2014 report, but now where uncertainty in the Expected values is measured about the WFD Reference-adjusted value ExpRef., this has been amended as described below.</p>
<p>Main algorithm used:</p>
<pre><code>ExpIDXir    = ExpIDXi +  ZExpir * SDExpi / √(NExpyear)</code></pre>
<p>Where (using the same notation as section 6.4 of the 2014 WHPT report):</p>
<pre><code>ExpIDXi  = WFD Reference-adjusted Expected value (ExpRef) of index i
ExpIDXir = WFD Reference-adjusted Expected value of index i in simulation r 
SDExpi   = Error SD for expected value of index i
NExpyear = 1 for single-year run
= number of years (1, 2 or 3) for which a separate estimate of the E value was involved in the estimate of average E value (for multi-year run) 
ZExpir  = Random number deviate from a standard Normal distribution with a mean of 0.0 and SD of 1.0, for use in simulation r for index i
  
</code></pre>
<p>Where:</p>
<pre><code>SDExp7 = 4.3 = Measurement error SD of Expected values of weighted WHPT Score (index 7)
SDExp8 = 0.53 = Measurement error SD of Expected values of weighted WHPT NTAXA (index 8)
SDExp9 = 0.081 = Measurement error SD of Expected values of weighted WHPT ASPT (index 9)</code></pre>
<p>Within RICT, these calculations are done using functions which can be found in the ClassificationfunctionsV2 (within the classification support files folder).</p>
<p>It should be noted that it is important to do this for each index and also be aware of the numbering for each index. As indicated above, each index has a number, i.e.:</p>
<ul>
<li>WHPT Score (index 7)</li>
<li>WHPT NTAXA (index 8)</li>
<li>WHPT ASPT (index 9)</li>
</ul>
</div>
<div id="user-input-of-observed-index-value-and-bias-calculation-of-bias-adjustment" class="section level2">
<h2 class="hasAnchor">
<a href="#user-input-of-observed-index-value-and-bias-calculation-of-bias-adjustment" class="anchor"></a>User input of observed index value and bias; calculation of bias adjustment</h2>
<p>(Step 6 in process diagram above)</p>
<p>RICT2 classification requires users to input an observed value for an index (ObsIDXi), based on samples collected in the field. This value is provided by the user completing the relevant data field in the input file as described in section 5 and Annex B of this document. Values are required for each index and for all three seasons, spring, summer and autumn.</p>
<p>Users may also input a bias value (UBiasis) for NTAXA, which reflects the impact of analytical error (measured by auditing) on the observed index values. This value is provided by the user completing the relevant data field in the input file as described in section 5 and Annex B of this document. RICT2 calculates bias for ASPT from bias for NTAXA and the observed NTAXA. If no input value for Bias is provided, RICT2 will use a default value of 1.62.</p>
<p>If bias correction is not wanted, users should enter a bias value of zero into the relevant data field in the input file. The zero value must be entered and not left blank or RICT2 will use a default value.</p>
</div>
<div id="simulate-uncertainty-in-observed-values" class="section level2">
<h2 class="hasAnchor">
<a href="#simulate-uncertainty-in-observed-values" class="anchor"></a>Simulate uncertainty in observed values</h2>
<p>(Step 7 in process diagram above)</p>
<p>These simulations take account of sampling error, estimated in replicated sampling studies, including the Biological Assessment Methods Study (BAMS) which is needed so that statistical confidence of the status classification can be estimated.</p>
<p>The main algorithm used:</p>
<pre><code>ObsIDXir = ObsIDXi ZNormir * SDObsi</code></pre>
<p>Where:</p>
<pre><code>ObsIDXi = input value provided by the user for observed value for an index as described in section 8.6 above
ZNormir = Random number deviate from a standard Normal distribution with a mean of 0.0 and SD of 1.0 for index i in simulation r
SDObsi  For single-year runs:  SDObsi    =  √( (SDRepi)2  +  (SDTSeasi)2)
Where values for SDRep = 0.269 and SDTSeas = 0.279
Definitions for each index used within RICT2 (which are only the abundance-weighted WHPT indices are as below copied from Section 6.3.3.2 (b) of the WHPT and other Abundance-Weighted Indices SEPA Report:
ObsIDX8r = (√(ObsIDX8) + ZObs8r)2 = rth simulated value for observed weighted WHPT NTAXA
ObsIDX9r = ObsIDX9 + ZObs9r = rth simulated value for observed weighted WHPT ASPT
ObsIDX7r = ObsIDX8r * ObsIDX9r = rth simulated value for observed weighted WHPT Score</code></pre>
<p>Within RICT2, these calculations are done using functions which can be found in the <code>classification-functions.R</code>.</p>
</div>
<div id="simulate-variation-in-bias" class="section level2">
<h2 class="hasAnchor">
<a href="#simulate-variation-in-bias" class="anchor"></a>Simulate variation in Bias</h2>
<p>(Step 8 in process diagram above)</p>
<p>This is simulation of user input bias which is calculated in RICT2 using the <code>getUbias8r()</code> function found in the <code>classification-functions.R</code>.</p>
<p>The algorithms used within this function are as below which is copied from Section 6.3.3.3 of the WHPT and other Abundance-Weighted Indices SEPA Report.</p>
<p>Definitions</p>
<pre><code>ObsIDXir = Simulation r Observed sample value of index i for current test site (uncorrected for bias)
  
Ubias8 = estimate of average net under-estimation of WHPT NTAXA for the observed sample</code></pre>
<p>Ubias8 is either:</p>
<ol style="list-style-type: decimal">
<li>input by the user of the RICT2 software</li>
<li>estimated as 36% higher than the user-input bias (Ubias2) for number of BMWP taxa i.e. Ubias8 = 1.36 Ubias2</li>
</ol>
<pre><code>Ubiasir   = Estimate of bias (net under-estimation) of index i for simulation r
ObsIDXirB = Bias-corrected observed value of index i for simulation r</code></pre>
<p>Special case : when no WHPT taxa were recorded in the sample (i.e. ObsIDX8 = 0), assume none were missed (i.e, set Ubias8 = 0)</p>
<pre><code>Ubias8r = bias (net under-estimate of number of WHPT taxa) for simulated sample r, estimated as a random deviate from a Poisson distribution with a mean of Ubias8
  
Zbias9r = Random number deviate from a standard Normal distribution with a mean of 0.0 and SD of 1.0
  
Ubias9r = abundance-weighted WHPT ASPT of the Ubias8r missed WHPT taxa for simulated sample r
  
  = u9a + u9b * ObsIDX9 + Zbias9r * (u9c / √Ubias8r)
  
where u9a = 4.35 , u3b = 0.271 , u9c = 2.5
  
Then: 
  
Ubias7r = Ubias8r * Ubias9r   =  bias of abundance-weighted WHPT score for simulated sample r
</code></pre>
</div>
<div id="correct-observed-values-for-bias" class="section level2">
<h2 class="hasAnchor">
<a href="#correct-observed-values-for-bias" class="anchor"></a>Correct observed values for bias</h2>
<p>(Step 9 in process diagram above)</p>
<p>The aim of this step is to use the values provided in the previous steps, add them together to give an overall calculated observed value corrected for Bias. Bias is a measure of the impact of laboratory error on the value of observed indices. It is calculated from audits of laboratory performance and is input by users as described in Section 8.6 above.</p>
<p>The main algorithm used is:</p>
<pre><code>ObsIDXirB = ObsIDXir + Ubiasir</code></pre>
<p>Where:</p>
<pre><code>ObsIDXirB   = Bias corrected observed value  
ObsIDXir    = Simulated observed value from Section 8.7 above  
Ubiasir     = Simulated Bias value from Section 8.8 above  </code></pre>
<p>Within RICT2, these calculations are done using functions which can be found in the ClassificationfunctionsV2 (within the classification support files folder).<br>
The algorithms used within this function are as below which is copied from Section 6.3.3.3 of the WHPT and other Abundance-Weighted Indices SEPA Report.</p>
<pre><code>ObsIDX7rB = ObsIDX7r + Ubias7r    =  bias-corrected observed abundance-weighted WHPT Score for simulation r
                                                                    
ObsIDX8rB = ObsIDX8r + Ubias8r    =  bias-corrected observed abundance-weighted WHPT NTAXA for simulation r
  
ObsIDX9rB = ObsIDX7rB / ObsIDX8rB   =  bias-corrected observed abundance-weighted WHPT ASPT for simulation r</code></pre>
<p>It should be noted as mentioned previously, that it is important to do this for each index and also be aware of the numbering for each index. As indicated above, each index has a number, i.e.:</p>
<ul>
<li>WHPT Score (index 7)</li>
<li>WHPT NTAXA (index 8)</li>
<li>WHPT ASPT (index 9)</li>
</ul>
<p>The simulated EQRs are stored for each metric at this point if required for Compare experiment.</p>
</div>
<div id="calculate-environmental-quality-ratio-eqr" class="section level2">
<h2 class="hasAnchor">
<a href="#calculate-environmental-quality-ratio-eqr" class="anchor"></a>Calculate Environmental Quality Ratio (EQR)</h2>
<p>(Step 10 in process diagram above)</p>
<p>The aim of this step is to express the observed value of the index as an indication of human impact by removing the effect of natural environmental conditions.</p>
<p>Status class boundaries for WFD are expressed as EQRs.</p>
<p>Simulated EQRs, based on simulated observed and expected values, are needed to estimate probabilities of class.</p>
<p>The main algorithm used is:<br><code>(EQRirB = (ObsIDXirB ÷ ExpIDXRef,ir)</code> Where:</p>
<pre><code>EQRirB         = simulated bias-corrected EQR value for index i   

ObsIDXirB    = Bias-corrected observed value of index i for simulation r as calculated in section 8.9.  
  
ExpIDXRef,ir    = Reference-adjusted Expected value of index i in simulation r as calculated in section 8.5.  </code></pre>
<p>This calculation is done directly within RICT2 code and not via any function.</p>
</div>
<div id="combine-spring-and-autumn-eqrs" class="section level2">
<h2 class="hasAnchor">
<a href="#combine-spring-and-autumn-eqrs" class="anchor"></a>Combine spring and autumn EQRs</h2>
<p>(Step 11 in process diagram above)</p>
<p>The aim of this step is to increase precision of classification and take account of seasonal variations in environmental quality.</p>
<p>The WFD status must be based on EQRs calculated from spring and autumn samples. These values must be calculated and available within the experiment for this step to calculate the seasonal average.</p>
<p>The EQR values for spring and autumn samples are divided by the number of season (i.e. 2) to calculate the seasonal average for each simulation.<br>
The main algorithm is:</p>
<pre><code>EQRirB,SpSuAu = (EQRirB,Sp + EQRirB,Au) / 2  </code></pre>
<p>Where:</p>
<pre><code>EQRirB,SpSuAu = Season average EQR  
EQRirB,Sp     = EQR value for spring season as calculated in section 8.10  
EQRirB,Au     = EQR value for autumn season as calculated in section 8.10 </code></pre>
<p>This is calculated in RICT2 using the getAvgEQR_SpAut () function found in the <code>classification-functions.R</code> (within the classification support files folder).</p>
</div>
<div id="determine-the-probability-of-the-class-being-high-good-moderate-poor-and-bad-status" class="section level2">
<h2 class="hasAnchor">
<a href="#determine-the-probability-of-the-class-being-high-good-moderate-poor-and-bad-status" class="anchor"></a>Determine the probability of the class being High, Good, Moderate, Poor and Bad status</h2>
<p>(Step 12 in process diagram above)</p>
<p>The aim of this step is to take account of imprecision in monitoring data in the classification.</p>
<p>The probability of each class is simply the sum of the simulations resulting in that class and is included in the output file.</p>
<p>As copied from Section 6.5 of the WHPT and other Abundance-Weighted Indices SEPA Report:</p>
<blockquote>
<p>“Confidence of class - The likelihood of the true status class (i.e. averaged across all possible samples) of a test site being each of the five possible WFD classes is estimated simply by applying the ‘status classification method’ to each simulation sample r in turn. Thus the class for simulation r is based on the EQI/EQR values for simulation r, namely the set of EQIir. For each index and overall, the proportion of simulations assigned to a status class estimates the probability that the true (average) quality of the test site for that time period was of that ecological status class (based on its macroinvertebrates).”</p>
</blockquote>
<p>So to summarise, the probability of each class is simply the sum of the simulations resulting in that class and this data is calculated and then included in the output file.</p>
</div>
<div id="determine-the-worst-class-indicated-by-whpt-aspt-and-whpt-ntaxa-using-minta" class="section level2">
<h2 class="hasAnchor">
<a href="#determine-the-worst-class-indicated-by-whpt-aspt-and-whpt-ntaxa-using-minta" class="anchor"></a>Determine the worst class indicated by WHPT ASPT and WHPT Ntaxa using MINTA</h2>
<p>(Step 13 in process diagram above)</p>
<p>The aim for this step is to ensure that the classification reflects ecological impacts caused by any type of environmental pressure.</p>
<p>The overall status class for a sample is defined to be the worst of classification based on number of taxa and ASPT. This is referred to as the MINTA class (i.e. MINimum of classes based on number of Taxa and ASPT).</p>
<p>The WFD status of a site or water body is based on the worst class indicated by either WHPT ASPT or WHPT Ntaxa, following the ‘one out all out’ rule.</p>
<p>The WFD requires that all water bodies, including rivers sites, are classified into one of five ecological status class. These classes in RICT2 are coded as classes 1-5 with 1= ‘high’, 2=‘good’, 3=‘moderate’, 4=‘poor’ and 5=‘bad’.</p>
<p>There are a number of processes involved in this step as described below:</p>
<ul>
<li>The EQR values calculated in section 10 above are used within the getClassFromEQR_ntaxa () function found in the <code>classification-functions.R</code> to find the class and relevant boundary limit values.</li>
<li>These values are then used within the getClassFromEQR_aspt () function found in the <code>classification-functions.R</code>.</li>
<li>The <code>getMostProbableClass()</code> function found in the <code>classification-functions.R</code> is used to find the most probable class.<br>
</li>
<li>The <code>getMINTA_ntaxa_aspt()</code> function found in the <code>classification-functions.R</code> is used to find the maximum of the two classes and which is the worst class. The worst class in then recorded in the output file and displayed in the MINTA column</li>
</ul>
</div>
<div id="classification-output" class="section level2">
<h2 class="hasAnchor">
<a href="#classification-output" class="anchor"></a>Classification output</h2>
<p>An output file will be created from running a project experiment to show the calculated data results of the experiment run for prediction and classification. The output file will also indicate any validation errors found during the run of the project experiment and specify which values resulted in either a “fail” or “warn”.</p>
<p>The output file will be in csv format to be downloaded by the user and used for reporting. There will be an output file available for prediction and an output file available for classification.</p>
</div>
</div>
<div id="multi-year-classification" class="section level1">
<h1 class="hasAnchor">
<a href="#multi-year-classification" class="anchor"></a>Multi Year Classification</h1>
<p>The aim of the multi-year experiment is to take account of temporary differences in quality and improve precision if a user has more than one year of sample data. River Invertebrate status must be assessed every 3 years for WFD. Where sites are sampled in a 3 year monitoring cycle, WFD status can be based on samples collected in more than one year.</p>
<p>Multi-year status classification takes account of inter-year variation based on observations from specific rivers and streams.</p>
<p>When the multi-year classification experiment is developed it will need to follow the agreed principles and process as described below:</p>
<ul>
<li>This will be a separate experiment that can be downloaded for any user wanting to carry out a multi-year classification.</li>
<li>Assessment is always on a 3 year period.</li>
<li>Users may supply 1, 2 or 3 years data.</li>
<li>A complete year’s data must include spring and autumn – otherwise this year cannot be included in the assessment.</li>
<li>Therefore minimum requirement is 1 year of data which includes spring and autumn.</li>
<li>Each year will be added as a separate row on the input file and for each year of data will have the same site name</li>
<li>RICT2 will check each row to see if it is same site name, if it is will store the simulations and include this in the assessment and will carry out this check for the next row to collect a maximum of 3 years of data.</li>
<li>There will be no changes needed to the input file as by the user selecting the multi-year experiment, RICT2 will be expecting multi-year data.</li>
<li>Ralph will be able to obtain some test data which can be used to clarify if the calculations are correct.</li>
<li>Output file will need to be amended to display the multi-year data and will display the term “multi-year” instead of the actual year in the Year column.</li>
<li>Apart from the differences highlighted above, the multi-year classification will follow the same process at the Prediction and Classification procedures specified in the previous sections of this document.</li>
</ul>
<p>We assume simple averaging based on the same number of samples involved in each year, but not necessarily the same seasons. There is therefore no problem (from a statistical point of view) if spring one year and autumn the next, but we do have a problem if year 1 = single season and Year 2 = 2-season classification. Basically, we assume the same sampling effort each year. However, remember that official WFD status classification must always be based on 2-season spring + autumn data.</p>
</div>
<div id="multi-site-classification-experiment" class="section level1">
<h1 class="hasAnchor">
<a href="#multi-site-classification-experiment" class="anchor"></a>Multi-site classification experiment</h1>
<p>The aim of multi-site classification experiment is to determine the overall status class for a water body based on samples collected from more than one site. The Environment Agency collects samples from some water bodies from more than one site.</p>
<p>The Environment Agency currently uses VISCOUS software to calculate WFD status for water bodies monitored from more than one site, as well as sites sampled in more than one year before 2019. Multi-site will allow the Environment Agency to replace VISCOUS completely, and therefore streamline the classification process. Multi-site classification uses similar algorithms to multi-year classification. Additionally, its output indicates which sites have been used.</p>
<p>As with multi-year, we assume simple averaging based on the same number of samples involved in each year within the water body (not necessarily the same seasons). There is therefore no problem (from the point of view of multi-year classification) if spring one year and autumn the next, but we do have a problem if year 1 = single season and Year 2 = 2-season classification. Basically, we assume the same sampling effort each year. However, remember that official WFD status classification must always be based on 2-season spring + autumn data.</p>
</div>
<div id="compare-project-experiment" class="section level1">
<h1 class="hasAnchor">
<a href="#compare-project-experiment" class="anchor"></a>Compare Project Experiment</h1>
<p>The relevant parts of the algorithms section of the SNIFFER WFD72C project 2008 Final Report have been extracted and adapted here to explain the algorithms needed to code the Compare procedure in the new R studio and Microsoft AZURE versions of the RICT software developed in 2019-20.</p>
<p>The new RICT only refers to EQR values (which are bias-corrected observed (Obs) values divided by WFD reference-adjusted Expected (ExpRef) values, all WFD72C algorithms section references to former EQI (Obs/Exp) values are replaced by their new counterpart EQR values to improve explanation of how to program the new RICT Compare procedure.</p>
<p>Compare flow chart:</p>
<p><img src="images/rict-compare.png" width="567" height="428"></p>
<p>The Compare procedure allows the user to assess whether there is a real difference in EQR values and/or status class between a pair of samples and/or sites and/or time periods. This is done using an extension of the simulation techniques and algorithms described above that are used to assess the EQRs and ecological status class and the associated uncertainty for individual samples/sites and time periods. The first sample in a pair is known as result A and the second as result B.</p>
<p>In each simulation r, independent simulated EQR values are calculated for each index i for each of the two results using the methods described in section 8.9 Correct observed values for bias. In this context, independent simulations means that the various random uncertainty terms are different and completely independent for the two simulated samples A and B for any simulation r.</p>
<p>Calculations for the EQR simulations are run as part of the classification process and are stored and available for output in each experiment. These EQR simulations can be saved and imported into the Compare experiment. To compare results, the two input files into Compare experiment must contain the same number of rows. The two files are then compared pair-wise, row to row for each result. For instance, if comparing a single upstream result to multiple downstream results, repeat the single result over multiple rows (equal to the number of downstream results) in the input file. Then run through the classification experiment and save results in Azure. Then run the downstream results through the classification and save dataset. Import both datasets into the Compare experiment and run.</p>
<p>Calculate Difference and Related Statistics:</p>
<pre><code>Average EQR for Results A = mean(EQRA)
Average EQR for Results B = mean(EQRB)
Average EQR: Difference (B- A) (DiffEQRirB) = EQRB – EQRA</code></pre>
<p>For each simulation r, the difference in the two simulated EQR values (sample B value minus sample A value) is calculated for each index i to give DiffEQRirB when corrected for bias.</p>
<pre><code>Standard Deviation of Difference = SD of the rN simulated values of EQIi (corrected for bias) for index i for the current test site</code></pre>
<p>Calculate the SD, (SDEQRi) of the rN values of EQRir in the usual way for calculating any SD.</p>
<pre><code>Lower 95% (L95) of Difference   = Lower 2.5 percentile of the rN simulated values (EQRir) of EQR (corrected for bias) for index i for the current test site
Upper 95% (U95) of Difference   = Upper 2.5 percentile of the rN simulated values (EQRir) of EQR </code></pre>
<p>Determine the lower and upper 2.5 percentiles and thus 95% confidence limits by sorting all of the rN simulated EQRir values into order from smallest to largest. Then the lower and upper percentiles are given by the mL and mU smallest values, where:</p>
<pre><code>mL  = nearest integer to 0.025 * (rN + 1)
mU  = nearest integer to 0.975 * (rN + 1) 
For the recommended rN = 9999, mL = 250   and mU = 9750.</code></pre>
<p>Confidence (and statistical test) of change/difference in EQR:</p>
<p>Confidence limits for the difference in EQR values are obtained from the frequency distribution of the differences (DiffEQRir) using the same approach as for single sample EQR values described above, namely, order the differences from smallest to largest and find the 2.5 and 97.5 percentile values of the order distribution.</p>
<p>Strictly speaking we can’t do a normal type of statistical test for the statistical significance of the difference (DiffEQRir) in EQR because we only actually have one sample on each occasion with no actually replication. However, we can generate a type of statistical test using the simulated EQI values, or more specifically, the frequency distribution of the simulated differences (DiffEQRir).</p>
<pre><code>PDiff0 = proportion of simulated differences less than or equal to zero.
PDiff1 = proportion of simulated differences greater than or equal to zero.
2-sided test probability p of No difference in EQR (PDiff) = 2 * minimum of (PDiff0, PDiff1)</code></pre>
<p>Then PDiff is the two-sided test probability of the null hypothesis of no difference in true EQR values between the sites and/or times from which the two samples were taken. [True EQR for a site, in this sense, means average EQI amongst all possible samples from the sites as estimated from the simulated values of EQR].</p>
<p>Code to calculate the difference and related statistics can be found in the compare_test() function. Note, that the simulated EQRs are randomly re-ordered (using set.seed). This is because the simulate EQRs are created in the rict_classify() using the same set.seed and will have equal variance add to each simulated EQR. Therefore, if we calculate the difference without re-ordering the result will be zero. In other words, the difference will cancel out. By re-ordering, we ensure the there will be a difference for each pair of EQRs compared.</p>
<p>Confidence of change in status class:</p>
<p>Each of the two simulated samples is assigned to a status class by applying the ‘status classification method’ independently to the simulated EQR values for each sample for that simulation. This is done repeatedly in rN simulations to build up a two-way frequency (and hence probability) distribution that the site (in its time period) from which sample A was taken was of status class ‘x’ (say) and the sites (in its time period) from which sample B was taken was of class ‘y’.</p>
<p>From this two-way probability distribution, the probability that samples A and B are from the same quality band can be estimated, together with the probabilities that sample B is one band better than A, one band worse, two or more bands better, or two or more bands worse.</p>
<p>In terms of RICT software, a 5 x 5 probability tables of changes is calculated internally using compare_probability() function. This is done for each index for which class limits are to be used and for each multi-index MINTA classification method.</p>
<p>In each case, a wide range of outputs are derived from this table and presented to the user as listed below.</p>
<p>If for coding purposes classes ‘high’ to ‘bad’ are referred to as classes 1-5 respectively, then</p>
<pre><code>PrChij       =  Proportion of simulations for which simulated sample A was classified as class i and simulated sample B was classified as class j.
                 =  Estimated probability of change in status from class i to class j</code></pre>
<p>Status class of sample B</p>
<p>high (1) good (2) mod (3) poor (4) bad (5) Status class of sample A high (1) PrCh11 PrCh12 PrCh13 PrCh14 PrCh15</p>
<p>good (2) PrCh21 PrCh22 PrCh23 PrCh24 PrCh25</p>
<p>mod (3) PrCh31 PrCh32 PrCh33 PrCh34 PrCh35</p>
<p>poor (4) PrCh41 PrCh42 PrCh43 PrCh44 PrCh45</p>
<p>bad (5) PrCh51 PrCh52 PrCh53 PrCh54 PrCh55</p>
<p>Find the most frequent class (random pick if equal frequency across two or more classes):</p>
<pre><code>Most Probable Class for Result A = most frequency class (status classification method(EQRA))

Probability of most likely class for Result A = Proportion in most probable class

Probability of most likely class for Result B = most frequency class (status classification method(EQRB))
  
Probability of most likely class for Result B = Proportion in most probable class
  
Probability status class of result(s) from which results A and B were taken is:
  
Both status class i = PrChii
  
Probability B more than one class Worse than A = sum of all { PrChij } for which j &gt; i + 1
  
Probability B one class Worse than A    = sum of all { PrChij } for which j = i + 1
  
Probability B same Class as A    = PrCh11 + PrCh22 + PrCh33 + PrCh44 + PrCh55
  
Probability B one class Better than A   = sum of all { PrChij } for which j = i – 1
  
Probability B more than one class Better than A = sum of all { PrChij } for which j &lt; I - 1</code></pre>
<p>Furthermore – extract each output from probability table in this order:</p>
<pre><code>Probability Result A in High &amp; Result B in High
Probability Result A in High &amp; Result B in Good
Probability Result A in High &amp; Result B in Moderate
Probability Result A in High &amp; Result B in Poor
Probability Result A in High &amp; Result B in Bad
Probability Result A in Good &amp; Result B in High
Probability Result A in Good &amp; Result B in Good
Probability Result A in Good &amp; Result B in Moderate
Probability Result A in Good &amp; Result B in Poor
Probability Result A in Good &amp; Result B in Bad
Probability Result A in Moderate &amp; Result B in High,
Probability Result A in Moderate &amp; Result B in Good
Probability Result A in Moderate &amp; Result B in Moderate
Probability Result A in Moderate &amp; Result B in Poor
Probability Result A in Moderate &amp; Result B in Bad
Probability Result A in Poor &amp; Result B in High
Probability Result A in Poor &amp; Result B in Good
Probability Result A in Poor &amp; Result B in Moderate
Probability Result A in Poor &amp; Result B in Poor
Probability Result A in Poor &amp; Result B in Bad
Probability Result A in Bad &amp; Result B in High
Probability Result A in Bad &amp; Result B in Good
Probability Result A in Bad &amp; Result B in Moderate
Probability Result A in Bad &amp; Result B in Poor
Probability Result A in Bad &amp; Result B in Bad</code></pre>
<p>Pivot all calculated variables (in bold above) to give one column per variable. Each row represents a pair of classification results.</p>
</div>
<div id="model-44-prediction-and-classification" class="section level1">
<h1 class="hasAnchor">
<a href="#model-44-prediction-and-classification" class="anchor"></a>Model 44 Prediction and Classification</h1>
<p>The Centre for Ecology and Hydrology (CEH) have produced a database of GIS environmental variables data for every 50m of steam or river for use with the new RIVPACS GB Model M44. T</p>
<p>This database will have a map-based location checker, to enable users to check that the Ordnance survey grid reference that they enter returns data for the catchment that they intended. Many monitoring sites are at the downstream end of rivers close to tributaries, so small error in the grid reference or GIS river line can cause the system to return data for the wrong river, and the database holds data only for one river within each 50m grid. The database holds all the environmental data for Model 44, derived from GIS, including discharge category but not including alkalinity.</p>
<p>This database has been hosted by <strong>Add details here</strong></p>
<p>This model produced by Ralph Clark and John Davey Bowker and based on these predictive variables is detailed in the report ‘GIS Re-calibration of the hydromorphology-independent RIVPACS predictive model (M37): new model M44’. <strong>(Add link?)</strong>.</p>
<p>RICT2 will be used with the new RIVPACS Model 44 to give better predictions of streams impacted by siltation due to flow alteration.</p>
<p>The majority of the coding that has been done in RICT2 for prediction and classification will also be suitable when running the experiment for the Model 44 prediction and classification.</p>
<p>With minor adjustments, the RICT2 prediction and classification code is suitable for running both Model 1 and Model 44 experiments.</p>
<p>The main areas of development involved understanding how to extract the data from RIVPACS and to link to a location checker as outlined in the picture below:</p>
<div id="model-44-validation" class="section level2">
<h2 class="hasAnchor">
<a href="#model-44-validation" class="anchor"></a>Model 44 Validation</h2>
<p>The GIS input spreadsheet may be needed for these values. However, it should be noted that these values will be provided by the model and not entered by a user.</p>
<p>Therefore validation requirements could be minimal as shown above. Validation may be required to check that values are numeric and not null.</p>
<p>It is expected that the experiment will be built first and then checks will be made on results produced to determine if some validation may be required, i.e. warnings and failures based on a limits amount.</p>
<p>Where a replacement value is available from the current RIVPACS IV GB or NI experiments, this has been used. But at this stage, there is no requirement for replacement values for new GIS based EVs used in Model 44. The GIS data layers provide EVs from pre-calculated datasets; therefore, replacement values are unlikely to be required.</p>
<p>Another difference is that there are now 17 discriminant function scores and discriminant function end group means scores rather than 13. See supporting files:</p>
<ul>
<li>discrimant-function-coefficients-model-44.csv</li>
<li>end-group-means-discriminant-scores-model-44.csv</li>
</ul>
<p>The flow diagram below summarises the prediction process and calculations as well as identifying the relevant report for further information:</p>
<p><img src="images/rict-prediction-model-44.png" width="576" height="432"></p>
<p>The flow diagram below summarises the classification process and calculations as well as identifying the relevant report for further information:</p>
<p><img src="images/rict-classification-model-44.png" width="577" height="432"></p>
</div>
</div>
<div id="non-functional-requirements" class="section level1">
<h1 class="hasAnchor">
<a href="#non-functional-requirements" class="anchor"></a>Non-Functional Requirements</h1>
<div id="operational-support" class="section level2">
<h2 class="hasAnchor">
<a href="#operational-support" class="anchor"></a>Operational Support</h2>
<p>The tool needs to be freely available for anyone to access online.</p>
<p>User support for EA users will be via the Defra service desk (at Tier 4 service level) who will route the issue to the appropriate team to deal with. This routing could be to RICT2 support email or to the Environmental systems team depending on the nature of the issue. EA users will also be able to access an article in MyIT which will provide FAQs to help users with common issues.</p>
<p>User support for other UK regulatory agency users will be via the support email box called RICT2 support.</p>
<p>There will be no official contracted support for external users but they can send issues and comments to the RICT2 support inbox</p>
</div>
<div id="look-and-feel-of-user-interface" class="section level2">
<h2 class="hasAnchor">
<a href="#look-and-feel-of-user-interface" class="anchor"></a>Look and Feel of User Interface</h2>
<p>The user interface will be provided via Azure Studio which is intuitive and ‘user friendly’ and consistent with similar windows-based or web-based user interface applications.</p>
<p>Official RICT2 experiments will be collated in a designated “Collection” in Microsoft Azure Learning Studio to help users find all the experiments relevant to RICT2.</p>
</div>
<div id="input-and-output-files" class="section level2">
<h2 class="hasAnchor">
<a href="#input-and-output-files" class="anchor"></a>Input and Output Files</h2>
<p>Input files will be a standard template in Excel which can be downloaded, completed by the user and then uploaded as a CSV file to RICT2. A user guide will be available to help users understand and complete the input file.</p>
<p>The output file will be produced by RICT2 as a CSV file following the run. A CSV file can easily be opened in Excel or other applications to view the results.</p>
</div>
<div id="hosting" class="section level2">
<h2 class="hasAnchor">
<a href="#hosting" class="anchor"></a>Hosting</h2>
<p>RICT2 is cloud hosted within Microsoft Azure Learning Studio.</p>
</div>
<div id="accessibility" class="section level2">
<h2 class="hasAnchor">
<a href="#accessibility" class="anchor"></a>Accessibility</h2>
<p>Access to RICT2 functionality may be required by a number of different device types. RICT2 will be useable at a minimum by the following device types (model not specified):</p>
<ul>
<li>Desktop</li>
<li>Laptop</li>
</ul>
<p>Access to RICT2 functionality may be required by a number of different browser types. RICT2 will be useable in the following browser types (which must be updated to the latest version as required by Microsoft Azure):</p>
<ul>
<li>IE</li>
<li>Google Chrome</li>
<li>Firefox</li>
<li>Edge</li>
</ul>
<p>Users will only have access to their own data and cannot access data input or output from other users.</p>
</div>
<div id="performance" class="section level2">
<h2 class="hasAnchor">
<a href="#performance" class="anchor"></a>Performance</h2>
<p>RICT2 will be accessible by multiple concurrent users at any one time without degradation of performance or limitation of features. Users will be internal EA, other UK regulatory body users (SEPA, NRW and NIEA) and external users.</p>
<p>RICT2 will be capable of processing the prediction and classification of a very large number of sites (approx. 5,000) once per year.</p>
<p>RICT2 will meet the following rough order estimates of service usage and performance requirements:</p>
<ul>
<li>Service Availability: In excess of 97% at all times;</li>
<li>Service Recovery: RTO (Recovery Time Objective) in 48 hours;</li>
<li>Maximum Nos. of Users: &lt;1000;</li>
<li>Max number of Concurrent Users: 50.</li>
</ul>
<p>RICT2 availability must be at an acceptable level. Planned downtime for maintenance must be advised in advance (minimum 48 hours’ notice). Unplanned downtime must be communicated regularly with up to date information on tools/services affected and projected downtime.</p>
</div>
<div id="system-administration" class="section level2">
<h2 class="hasAnchor">
<a href="#system-administration" class="anchor"></a>System Administration</h2>
<p>An “expert” user (system administrator) will be identified and given permission to publish new standard experiments using default values to the “official” Microsoft Azure ML Studio gallery collection.</p>
<p>These experiments will be “locked down” for normal users and can only be amended by downloading to the users own work area to create their own copy of a project experiment.</p>
<p>The System administrator will be permitted to amend the published standard experiments and the data tables used by the experiment (e.g. amend end group data) if required.</p>
</div>
<div id="data-protection" class="section level2">
<h2 class="hasAnchor">
<a href="#data-protection" class="anchor"></a>Data Protection</h2>
<p>Data protection requirements are handled by Microsoft as the tool is hosted on Microsoft ML Studio. It is freely available to access but requires the user to use an existing/or create a Microsoft account. This account requires an email address and password. These credentials are held solely by Microsoft and the usage is outlined in the Microsoft Privacy Statement (<a href="https://privacy.microsoft.com/en-gb/privacystatement" class="uri">https://privacy.microsoft.com/en-gb/privacystatement</a>).</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Maybin Muyeba, Tim Foster.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
